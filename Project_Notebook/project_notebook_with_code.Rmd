---
title: The Impact of NBA player-related Social Media Posts on their on-court Performance
  - An Analysis
author: "Frank Dreyer, Kolja Günther, Jannik Greif"
date: "20.05.2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
subtitle: DataSciR - Project Notebook
bibliography: references.bib
csl: ieee.csl
header-includes:
- \usepackage{titling}
- \pretitle{\begin{center} \includegraphics[width=2in,height=2in]{"datascir.png"}\LARGE\\}
- \posttitle{\end{center}}
link-citations: yes
---

```{r setup, include=FALSE, eval = TRUE}
knitr::opts_chunk$set(echo = TRUE)
# get-tweets packages
library(tidyverse)
library(rtweet)
library(academictwitteR)
library(anytime)
# nba-stats packages
library(rvest)
library(naniar)
# pre-processing packages
library(stringr)
library(textclean)
# sentiment extraction packages
library(magrittr) # for %$% operator
library(sentimentr)
# analysis packages
library(ggpubr)
library(tidytext)
library(ggwordcloud)
# predictive model packages
library(lubridate)
library(purrr)
library(rvest)
library(ranger)
library(tidymodels)

knitr::opts_chunk$set(
  echo = FALSE, 
  eval = FALSE, 
  message = FALSE,
  warning = FALSE,
  fig.show = "asis"
)

data_dir <- "../data"
tweets_dir <- data_dir %>% paste("tweets", sep = "/")
sentiments_dir <- data_dir %>% paste("sentiments", sep = "/")

# Twitter Api Credentials
twitter_app_name <- "DataSciR"
twitter_api_key <- "he8beW6mFPz12r8QiqtXsZbLN" # Insert API key here
twitter_api_secret_key <- "yFnZfhVitCl9fWixlImG6BRGkCX7c2HjlggHv3HgSYtnJIDokX" # Insert API key secret here
twitter_access_token <- "1397627861503287305-8YHK3ANCzUt0x0Ufdb1OICJ75i4fns" # Insert access token here
twitter_access_token_secret <- "cbK5fyPzVLtczRmWnMiDuZOLrvSaJldaSDQRZ31Hubgki" # Insert access token secret here
twitter_bearer_token <- "AAAAAAAAAAAAAAAAAAAAAMJSQAEAAAAAxo6ezvCA34%2F%2B1gBbknootwxLdqs%3DtP8sqsQarCLEhnQXuFYXN79PxWfpG0btbSvDmBEZfePpM23Zyy" # Insert bearer-token here

twitter_token <- create_token(
  app = twitter_app_name,
  consumer_key = twitter_api_key,
  consumer_secret = twitter_api_secret_key, 
  access_token = twitter_access_token,
  access_secret = twitter_access_token_secret
)
```

\newpage

## Github Repository

The project is documented at: https://github.com/jannikgreif/DataSciR_2021


## Team Members

```{r team, eval = TRUE}
library(knitr)
library(kableExtra)
team <- data.frame(Name = c("Jannik Greif","Kolja Günther","Frank Dreyer"),
                   `Course of Studies` =c("M.Sc. Wirtschaftsinformatik","M.Sc. Data and Knowledge Engineering","M.Sc. Data and Knowledge Engineering"),
                  Mail = c("jannik.greif@st.ovgu.de","kolja.guenther@st.ovgu.de","frank.dreyer@st.ovgu.de"), check.names = FALSE)
kbl(team, booktabs = T, linesep = "") %>%
  kable_styling(position = "center")%>%
  kable_styling(latex_options = "HOLD_position")
```

## 1. Overview
The present project aims to discover a significant impact of social media posts addressed to NBA players before matches with respect to their influence on these players’ in-game performance. For this purpose, we considered NBA players that are highly active on Twitter and extracted tweets that are addressed to them within a short period of time before matches via the Twitter API. A sentiment analysis was then applied to indicate the attitude of the posts and with the resulting sentiment polarity scores we tested if there is a correlation between social media posts and players’ on-court performance.

## 2. Motivation and Related Work
With the growing presence of social media in all areas of life, allowing people from around the world to react to current events in real-time, an increasingly controversial discussion can be noticed. Today more than ever, public figures are exposed to the reactions of millions of people, observing and commenting on every step in their life that becomes public. The resulting negative impact that extensive social media usage can have on users' behavior and mental state is subject to different scientific studies [-@kapoor_advances_2018;-@berryman_social_2018]. 
 
Sports athletes, who use social media not only to communicate with peers and fans but also to promote themselves, are no exception to these issues [-@academy_does_2008]. Among researchers in the sports field, there is a consensus that the mental state of an athlete can have a significant impact on his or her performance [-@xu_measuring_2015]. However, only little research has been conducted in order to analyze if and how social media usage of athletes directly influences their performance.
Xu and Yu [-@xu_measuring_2015] tried to capture the mood of basketball players in the NBA from the tweets they posted just before a match, using sentiment analysis, to analyze how the predicted mood influenced their performance on court. Gruettner, Vitisvorakarn and Wambsganss [-@gruttner_new_2020] used a similar approach on tennis players and additionally analyzed the relationship between the number of tweets they posted before matches and their performance within the match. Even though both contributions show that athletes with a bad predicted mood tend to perform worse on-court, they suffer from two limitations: 
 
  1.    The number of tweets an athlete posts per day is rather limited 
  2.    The predicted moods are not free of bias since an athlete might only post tweets how he or she wants to be seen on Twitter (also indicated in [-@gruttner_new_2020])
 
Both of these limiting factors may lead to an inaccurate prediction of the mental state of athletes. \newline

We believe that the attitude of social media posts an athlete receives from peers and fans is also a good predictor for his or her performance. Ott and Puymbroeck support this claim  [-@academy_does_2008]. In their article they list cases where athletic performance appeared to be immediately influenced by the media and conclude that the media has the potential to change the performance of an athlete in a negative as well as positive way. In this analysis we aim to assess this relationship more closely by analyzing how social media posts addressed to NBA players affect their in-game performance.

## 3. Initial Research Questions and Project Objectives
In the beginning of our project we want to give a brief overview on our research goal and the tasks we want to fulfill.\newline
This project aims to answer the following research question: \newline
**Can we find a significant correlation between negative/positive Social Media posts related to a specific NBA player and his on-court performance in the following game?**\newline

To answer this research question we worked on the following objectives:\newline

**Objective 1: Dataset Creation** \newline
Acquire game statistics of NBA players that are highly active on Twitter and the tweets they received from peers and fans in an appropriate time window before games. The game statistics should include an appropriate metric that describes how the player performed within a corresponding game. The tweets need to be preprocessed accordingly to have them in an appropriate format in order to use them for further analysis steps. The attitude of the extracted posts should be captured by assigning a sentiment score to them. The sentiment scores of the tweets a player received in the corresponding time window before a game should be aggregated accordingly and linked to the respective game. As a result, this should end in a data set in which each record contains the game statistics of a player for a specific game and the aggregated sentiment information of the tweets that were addressed to the player before the game. 

**Objective 2: Exploratory Data Analysis** \newline
Analyze the association between the aggregated polarity scores of the tweets a player received before games and the performance of the player within the games using appropriate performance metrics. Additionally, the strength and significance of the correlation should be evaluated. 

**Additional objective 3: Prediction Model ** \newline
After we investigated the results of our analysis we decided to additionally set up a prediction model to check the findings we made. With this model we wanted to explore the influence of tweet sentiments on a prediction task of a NBA players' on-court performance. For this purpose we fed our sentiments as features into the predictor.

## 4. The Data
The main challenge in the pre-processing phase of our project was to create suitable datasets. For the players' performance variable we needed to create a set of datasets which cover all necessary statistics and metadata to be able to derive the needed values. For the sentiment variable of the tweets referring to one respective game and player, we first needed to narrow down the selection of players whose tweets we wanted to observe and then extract all tweets that are related to this set of players. How this was done is described in the following section.

### 4.1 NBA Stats Datasets

#### 4.1.1 Introduction

To get the needed data about players, games, seasons and all relevant metadata, we extracted statistical datasets from [basketball-reference.com](https://basketball-reference.com), a site which provides historical basketball statistics of players and teams from various US American and European leagues including the NBA. From this we created local .csv files for different metrics.

#### 4.1.2 Setup & Extracting Player Metadata
To get started, we set up our environment and for extracting the data from [basketball-reference.com](https://basketball-reference.com) we extensively used the web scraping library `rvest` in addition to the `tidyverse`.

Before extracting stats about NBA players and games, we had to check, which players even have a twitter account. Fortunately for us, [basketball-reference.com](https://basketball-reference.com) provides a list of [Twitter usernames of NBA players](https://www.basketball-reference.com/friv/twitter.html), so we loaded the account names into the player-metadata.csv, along with an unique BBRef_Player_ID, which we took over from [basketball-reference.com](https://basketball-reference.com), and the clear name of the respective players.
With this set of players we now wanted to extract further statistics.

```{r player-metadata}
url <- "https://www.basketball-reference.com/friv/twitter.html"

metadata_tbl <- read_html(url) %>% 
  html_element("table.stats_table") 

player_td = metadata_tbl %>% 
  html_elements("td[data-stat=\"player\"]") 

twitter_td = metadata_tbl %>% 
  html_elements("td[data-stat=\"twitter\"]")

BBRef_Player_IDs = player_td %>% 
  html_element("a") %>% 
  html_attr("href") %>% 
  map_chr(~ str_extract(.x, "[a-z]/[a-z]+[0-9]{2}"))

player_names = player_td %>% html_text(trim = TRUE)

twitter_names = twitter_td %>% html_text(trim = TRUE)

metadata <- tibble(
  BBRef_Player_ID = BBRef_Player_IDs,
  Player = player_names,
  Twitter = twitter_names
)

file_path <- data_dir %>% paste("player-metadata.csv", sep = "/")
metadata %>% write_csv(file_path)
```

```{r show-player-metadata, eval = TRUE}
player_metadata <- data_dir %>% 
  paste("player-metadata.csv", sep = "/") %>% 
  read_csv()

player_metadata %>%
  head(100)
```

#### 4.1.3 Getting Player Season Statistics
The idea behind this dataset was to create a tibble which included all the statistics of players on season-level. As a basketball season is split into a regular season (comparable to our "Bundesliga"-system) and a playoff season (comparable to a tournaments k.o.-phase) which only the best teams of one regular season can pass, [basketball-reference.com](https://basketball-reference.com) provides two separate datasets, one for each season type.
To combine those datasets and map them to each player in one table, we set up loops, that check for each season, whether a player actively participated in either the regular season and/or the playoffs, extract the statistics if the condition holds true and tag each tuple of either the regular season statistics or the playoff statistics with a respective label "Regular Season" or "Playoffs". If one player didn't participate in any of the both possibilities, we set all variables of this entry to NA. This step is necessary as the original data labels each variable entry with a respective string, like "Did not play" or "Inactive"
Finally the dataset contained one tuple of statistics for each player and season/seasontype he participated in, including the following metrics:

```{r basketball-reference, echo = FALSE}
library(knitr)
table <- data.frame(
  Attribute = c("Starters / Reserves","MP","FG","FGA","FG%","3P","3PA","3P%","FT","FTA","FT%","ORB","DRB","TRB","AST","STL","BLK","TOV","PF","PTS","+/-"),
  `Data Type` = c("String","Timediff","Int","Int","Float","Int","Int","Float","Int","Int","Float",rep("Int",times=10)),
  Description = c("Name of player (separated in starters and reserves)","Minutes Played","Field Goals: number made shots (excluding free throws)","Field Goal Attempts = number of shot attempts (excluding free throws)","Field Goal Percentage: fraction of field goal attempts (FG/FGA)","3-Point Field Goals: number of made 3-point shots","3-Point Field Goal Attempts: number of 3-point shot attempts","3-Point Field Goal Percentage: fraction of three point shot attempts (3P/3PA)","Free Throws: number of free throw shots ","Free Throw Attempts: number of free throw shot attempts","Free Throw Percentage: fraction of free throw attempts (FT/FTA)","Offensive Rebounds","Defensive Rebounds","Total Rebounds (ORB+TRB)","Assists","Steals","Blocks","Turnovers","Personal Fouls","Points made","Estimates the players’ contribution to the team when the player is on the court"), check.names = FALSE
)
kbl(table, booktabs = T, linesep = "") %>%
  kable_styling(position = "center") %>%
  kable_styling(latex_options = "HOLD_position") %>%
  kable_styling(latex_options = "striped")
```

```{r player-season-stats}
get_player_season_stats <- function(BBRef_Player_ID) {
  
  url <- glue::glue("https://www.basketball-reference.com/players/{BBRef_Player_ID}.html")
  html <- read_html(url)
  
  html_regular_season_tbl <- html %>% html_node("table#per_game")
  html_playoffs_tbl <- html %>% html_node("table#playoffs_per_game")
  
  season_stats <- NULL
  regular_season_stats <- NULL
  playoffs_season_stats <- NULL
  
  # If player participated in regular season
  if (!is.na(html_regular_season_tbl)) {
    regular_season_stats <- html_regular_season_tbl %>% 
      html_table(trim = TRUE, convert = FALSE) %>% 
      mutate(SeasonType = "Regular Season", .after = Season)
  }
  
  # If player participated in playoffs
  if (!is.na(html_playoffs_tbl)) {
    playoffs_season_stats <- html_playoffs_tbl %>% 
      html_table(trim = TRUE, convert = FALSE) %>% 
      mutate(SeasonType = "Playoffs")
  }
  
  # If player participated in regular season or playoffs
  if (! is.null(regular_season_stats) | ! is.null(playoffs_season_stats)){
    season_stats <- regular_season_stats %>%
      bind_rows(playoffs_season_stats) %>% 
      filter(str_detect(Season, "[0-9]{4}-[0-9]{2}")) %>%   
      mutate(BBRef_Player_ID = BBRef_Player_ID, .before = Season) %>% 
      naniar::replace_with_na_all(
        condition = ~ str_detect(.x, "Did Not Play")
      ) %>% 
      type.convert(as.is = TRUE)
  }
  
  season_stats
  
}

player_season_stats <- player_metadata$BBRef_Player_ID %>% 
  map_dfr(get_player_season_stats) %>% 
  mutate(Team = if_else(! is.na(Tm), Tm, Team)) %>% 
  select(-Tm)


file_path <- data_dir %>% paste("player-season-stats.csv")
player_season_stats %>% write_csv(file_path)
```

```{r load-player-season-stats, eval = TRUE}
player_season_stats <- data_dir %>% 
  paste("player-season-stats.csv", sep = "/") %>% 
  read_csv()
```

```{r display-player-season-stats, eval = TRUE, message = TRUE}
player_season_stats %>%
  head(100)
```

#### 4.1.4 Extracting Player Game Statistics
The next step was to extract performance statistics of the NBA-players on game-granularity. With this we wanted to create our main source for the performance indicators, which we wanted to exploit for our exploratory analysis.
According to [Wikipedia](https://en.wikipedia.org/wiki/Twitter) Twitter was found in 2006. Probably not many NBA players had a Twitter account during that time. In 2007 only 400,000 tweets were posted per quarter. However, the popularity of Twitter skyrocketed after its founding with over 50 million daily tweets in 2010. Let's therefore only consider players that actively played from 2010 onward. 
Since player performance metrics like +/- become rather unreliable if a player only gets a small amount of playing time, we only considered players that on average get at least two quarters of playing time (i.e. 24 minutes).

```{r filter-relevant-players, eval = TRUE}

min_MP <- 24
min_Season <- "2010"

relevant_players <- player_season_stats %>% 
  filter(Season >= min_Season) %>% 
  group_by(BBRef_Player_ID) %>% 
  summarise(
    AVG_MP = mean(MP, na.rm = TRUE)
  ) %>% 
  ungroup() %>% 
  filter(AVG_MP >= min_MP) 

```

```{r display-relevant-player, eval = TRUE, message = TRUE}
relevant_players %>%
  head(100)
```

In detail the player-game-stats.csv contains for each player/game combination within our observation range a detailed set of metadata, like the season type and date of the game or the team for which the player started, as well as individual performance statistics for each game, like the ones we also extracted for the season statistics but on game-granularity plus extra metrics that can be obtained for each game individually. While the already known statistics were obtained from the basic game logs, the additional data was extracted from the advanced game logs. With these advanced statistics we also added the Box Plus/Minus score, "a box score estimate of the points per 100 possessions a player contributed above a league-average player (defined as being 0.0), translated to an average team." as described [here.](https://www.basketball-reference.com/about/bpm2.html)
This metric is calculated from the box score information of a player, his position on-court, and the overall performance of the team. Explained on an example, a score of +10.0 would mean, that the overall team is 10 points per 100 possessions better with this particular player on-court than with an average player. It should become the central metric of player performance for our correlation analysis.

```{r player-game-stats}

not_played_keys <- c(
  "Did Not Play", 
  "Did Not Dress", 
  "Inactive",
  "Not With Team",
  "Player Suspended"
)


get_player_game_stats <- function(BBRef_Player_ID) {
  
  print(BBRef_Player_ID)
  
  url <- glue::glue("https://www.basketball-reference.com/players/{BBRef_Player_ID}.html")
  html <- read_html(url)
  
  player_seasons <- get_player_seasons(BBRef_Player_ID)
  BBRef_Player_ID_rep <- rep(BBRef_Player_ID, times = player_seasons %>% length())
  
  basic_gamelogs <- map2_dfr(
    BBRef_Player_ID_rep, player_seasons, ~ get_gamelogs(.x, .y, "basic")
  ) 
  
  advanced_gamelogs <- map2_dfr(
    BBRef_Player_ID_rep, player_seasons, ~ get_gamelogs(.x, .y, "advanced")
  )
  
  gamelogs <- inner_join(basic_gamelogs, advanced_gamelogs) %>% 
    type.convert()
  
  gamelogs
  
}


get_player_seasons <- function(BBRef_Player_ID) {
  
  url <- glue::glue("https://www.basketball-reference.com/players/{BBRef_Player_ID}.html")
  html <- read_html(url)
  
  seasons <- html %>% 
    html_elements("th[data-stat=\"season\"]") %>% 
    html_element("a") %>% 
    html_text() %>% 
    unique() %>% 
    na.omit()
  
  seasons
  
}


get_gamelogs <- function(BBRef_Player_ID, season, gamelog_type) {
  
  url <- glue::glue(
    "https://www.basketball-reference.com/players/{id}/gamelog{type}/{s}",
    id = BBRef_Player_ID,
    type = if_else(gamelog_type == "basic", "", paste("", gamelog_type, sep = "-")),
    s = season %>% 
      str_remove("[0-9]{4}-") %>% 
      paste("0101", sep = "") %>% 
      lubridate::ymd() %>% 
      lubridate::year()
  )
  html <- read_html(url)
  
  print(url)
  
  html_regular_season_gamelog_tbl <- html %>%  
    html_node(glue::glue("table#pgl_{gamelog_type}"))
  
  # Playoffs game logs embedded in HTML comment
  html_playoffs_gamelog_tbl <- html %>% 
    html_nodes(xpath = '//comment()') %>% 
    html_text() %>% 
    paste(collapse = '') %>% 
    read_html() %>% 
    html_node(glue::glue("table#pgl_{gamelog_type}_playoffs"))
  
  regular_season_gamelogs <- NULL
  playoffs_gamelogs <- NULL
  gamelogs <- NULL
  
  # If player participated in regular season game
  if (!is.na(html_regular_season_gamelog_tbl)) {
    regular_season_gamelogs <- html_regular_season_gamelog_tbl %>% 
      html_table(trim = TRUE, convert = FALSE, header = NA) 
    
    names(regular_season_gamelogs)[6] <- "HTm"
    names(regular_season_gamelogs)[8] <- "WL"
    
    regular_season_gamelogs <- regular_season_gamelogs %>% 
      mutate(SeasonType = "Regular Season", .before = Date)
  }
  
  # If player participated in playoffs game 
  if (!is.na(html_playoffs_gamelog_tbl)) {
    playoffs_gamelogs <- html_playoffs_gamelog_tbl %>% 
      html_table(trim = TRUE, convert = FALSE, header = NA)
    
    names(playoffs_gamelogs)[6] <- "HTm"
    names(playoffs_gamelogs)[8] <- "WL"
    
    playoffs_gamelogs <- playoffs_gamelogs %>% 
      mutate(SeasonType = "Playoffs", .before = Date)
  }
  
  # If player participated in regular season or playoffs
  if (!is_null(regular_season_gamelogs) | !is_null(playoffs_gamelogs)) {
    gamelogs <- regular_season_gamelogs %>%
      bind_rows(playoffs_gamelogs) %>% 
      filter(Date != "Date") %>%      # Filter out header rows
      mutate(Season = season, .before = SeasonType) %>% 
      mutate(BBRef_Player_ID = BBRef_Player_ID, .before = Season) %>% 
      mutate(HTm = if_else(HTm == "@", Opp, Tm)) %>% 
      naniar::replace_with_na_all(~ .x %in% not_played_keys) %>% 
      mutate(BBRef_Game_ID = map2_chr(
        Date, HTm, 
        ~ paste(lubridate::ymd(.x) %>% format("%Y%m%d"), .y, sep = "0")
      ), .after = BBRef_Player_ID) %>% 
      type.convert(as.is = TRUE)
  }
  
  gamelogs
  
}


get_game_time <- function(game_url) {
  
  read_html(game_url) %>% 
    html_element("div.scorebox_meta") %>% 
    html_text() %>% 
    str_extract("[0-9]{1,2}:[0-9]{2} [A|P]M")
    
}


subselection <- relevant_players %>% head()

player_game_stats <- relevant_players$BBRef_Player_ID %>%
  map_dfr(get_player_game_stats)

file_path <- data_dir %>% paste("player-game-stats.csv", sep = "/")
player_game_stats %>% write_csv(file_path)
```

```{r load-player-game-stats, eval = TRUE}
player_game_stats <- data_dir %>% 
  paste("player-game-stats.csv", sep = "/") %>% 
  read_csv()
```

```{r display-player-game-stats, eval = TRUE, message = TRUE}
player_game_stats %>%
  head(100)
```

#### 4.1.5 Creating Game Metadata
The last data source we wanted to create, was a table of metadata for each game. For this purpose we extracted the NBA schedule and results from [basketball-reference.com](https://basketball-reference.com) for each season from 2010 to 2021 column-wise and merged these columns into one tibble. This was then stored in the game-metadata.csv.

```{r game-metadata, eval = FALSE}

get_game_metadata <- function(season) {
  
  year <- season %>% str_remove("[0-9]{4}-") %>% 
    paste("0101", sep = "") %>% 
    lubridate::ymd() %>% 
    format("%Y")
  
  url <- glue::glue("https://www.basketball-reference.com/leagues/NBA_{year}_games.html")
  html <- read_html(url)
  
  game_metadata <- html %>% 
    html_element("div.filter") %>%
    html_elements("a") %>% 
    html_attr("href") %>% 
    map_dfr(get_game_schedule)
  
  game_metadata
  
}


get_game_schedule <- function(url) {
  
  url <- glue::glue("https://www.basketball-reference.com{url}")
  html <- read_html(url)
  
  html_schedule_tbl <- html %>% html_node("table#schedule")
  
  game_dates <- html_schedule_tbl %>% 
    html_element("tbody") %>% 
    html_elements("th[data-stat=\"date_game\"]") %>% 
    html_element("a") %>% 
    html_text2() %>% 
    lubridate::mdy()
  
  game_start_times <- html_schedule_tbl %>% 
    html_element("tbody") %>% 
    html_elements("td[data-stat=\"game_start_time\"]") %>% 
    html_text2() %>% 
    paste0("m")
  
  game_home_teams <- html_schedule_tbl %>% 
    html_element("tbody") %>% 
    html_elements("td[data-stat=\"home_team_name\"]") %>% 
    html_attr("csk") %>% 
    str_sub(start = 1, end = 3)
  
  game_home_pts <- html_schedule_tbl %>% 
    html_element("tbody") %>% 
    html_elements("td[data-stat=\"home_pts\"]") %>% 
    html_text2()
  
  game_visit_teams <- html_schedule_tbl %>% 
    html_element("tbody") %>% 
    html_elements("td[data-stat=\"visitor_team_name\"]") %>% 
    html_attr("csk") %>% 
    str_sub(start = 1, end = 3)
  
  game_visit_pts <- html_schedule_tbl %>% 
    html_element("tbody") %>% 
    html_elements("td[data-stat=\"visitor_pts\"]") %>% 
    html_text2()

  schedule <- tibble(
    Date = game_dates,
    Start = game_start_times,
    HomeTm = game_home_teams,
    HomePTS = game_home_pts,
    VisitTm = game_visit_teams,
    VisitPTS = game_visit_pts
  ) %>% 
    mutate(DateTime = map2_chr(Date, Start, paste), .before = Date) %>% 
    mutate(DateTime = lubridate::ymd_hm(DateTime)) %>% 
    mutate(BBRef_Game_ID = map2_chr(
      Date, HomeTm, ~ format(.x, "%Y%m%d") %>% paste(.y, sep = "0")
    ), .before = DateTime)
  
}

game_metadata <- player_season_stats %>% 
  filter(Season >= min_Season) %>% 
  pull(Season) %>% 
  unique() %>% 
  map_dfr(get_game_metadata)

file_path <- data_dir %>% paste("game-metadata.csv", sep = "/")
game_metadata %>% write_csv(file_path)

```

```{r load-game-metadata, eval = TRUE}
game_metadata <- data_dir %>% 
  paste("game-metadata.csv", sep = "/") %>% 
  read_csv()
```

As you can see in the table below, the metadata we extracted contains for each match the date and starting time, the home team with their respective points and the visitor team with their respective points.

```{r display-game-metadata, eval = TRUE, message = TRUE}
game_metadata %>%
  head(100)
```

### 4.2 Getting the Twitter Data
The Twitter dataset contains all tweets related to the players we want to inspect in our analysis for their on-court performance and this part of the notebook contains the whole pipeline of extracting these relevant tweets. But before we were able to exploit the API, some pre-work had to be done.
First, we set up the main directory for our data to be created and the datasets we previously created from [basketball-reference.com](https://basketball-reference.com) get loaded. In the next step and before we could start with the extraction of relevant tweets for our NBA players, we had to narrow down the number of players to be considered by our pipeline. The datasets above include over 227 players. As the process of collecting tweets for such a number of players would be a huge overload, we decided to pick those top players, which are most relevant for us, following some criteria we set up in the following.

```{r read_nba_data, eval = TRUE}
player_metadata <- paste(data_dir,"player-metadata.csv", sep ="/") %>% read_csv()
player_game_stats <- paste(data_dir,"player-game-stats.csv", sep ="/") %>% read_csv()
game_metadata <- paste(data_dir,"game-metadata.csv", sep ="/") %>% read_csv()
player_season_stats <- paste(data_dir,"player-season-stats.csv", sep ="/") %>% read_csv()
```

#### 4.2.1 Players who played actively for the same team
First of all we picked those players, which continuously played in the regular seasons 2016/17 - 2018/19. We didn't consider the playoffs here, as many players don't get into the playoffs with their teams but still play a full regular season and therefore provide enough interesting game-data for our analysis. Furthermore, we only wanted those players in our dataset, who stayed at their respective team for the whole time of observation. The idea behind this was to eliminate team switches as possible factors that influence the players' performance. Additionally we considered only those players who had on-court time in at least 80% of the games during their regular season.

#### 4.2.2 Players whose BPM varied by a standard deviation of at least 8
As third parameter we inspected the variable "Box Plus/Minus" (BPM) in the player_game_stats dataset, which is a score-based performance indicator that already was briefly introduced in the section before.
With this estimate, we wanted to extract those players, whose performance is relatively unstable in comparison to their colleagues by computing the standard deviation of performance for each player and storing them from the highest deviation in descending order. On this dataset we applied a cutoff value to get only those players, whose standard deviation was higher or equal to 8. The assumption behind this filter parameter was, that an influence of social media on the performance could only be observed, when there is a change in performance over the whole observation period. On players who have a stable performance, we would not be able to measure an impact if there was no/just very little change.

#### 4.2.3 Players with at least 1.000 followers
The last parameter we wanted to include into our selection concerned about the players who have a minimal follower count of 1.000 users on Twitter. For this we joined our data with the Twitter metadata we extracted along with the tweets themselves and addressed the variable 'follower_count' to be at least of size 1.000. Similar to the prior filter condition, the idea behind this was to have only players in consideration, who have possibly enough tweets that could generate an impact on their performance. The assumption: Players with less than 1.000 followers are very likely to don't get a sufficient amount of tweets for our observations. Finally we then filtered our 'relevant_players' tibble by an inner join with this selection on their common variable 'screen_name'.

```{r select_relevant_players, eval = TRUE}
relevant_players <- player_season_stats %>% 
  
  # Players who played actively (>= 80% of games) for the same team between 2016-2019 (3 seasons)
  filter(Season %in% c("2016-17", "2017-18", "2018-19")) %>% 
  filter(SeasonType == "Regular Season") %>% 
  group_by(BBRef_Player_ID) %>% 
  filter(n() == 3) %>% 
  summarise(
    team_cnt = length(unique(Team)),
    game_cnt = sum(G)
  ) %>% 
  filter(team_cnt == 1) %>% 
  filter(game_cnt >= 0.8 * 82 * 3) %>% 
  select(BBRef_Player_ID) %>% 
  
  # Players whose BPM varied by a standard deviation of at least 8
  inner_join(player_game_stats) %>% 
  group_by(BBRef_Player_ID) %>% 
  summarise(sd_BPM = sd(BPM, na.rm = TRUE)) %>% 
  filter(sd_BPM >= 8) %>% 
  select(BBRef_Player_ID) %>% 
  
  # Players with at least 1000 followers
  inner_join(player_metadata) %>% 
  pmap_dfr(function(...){
    relevant_player <- tibble(...)
    twitter_meta <- relevant_player$Twitter %>% 
      lookup_users(token = twitter_token) %>% 
      select(c("screen_name", "followers_count"))
    inner_join(relevant_player, twitter_meta, by = c("Twitter" = "screen_name"))
  }) %>% filter(followers_count >= 1000) %>% 
  select(player_metadata %>% names())
```

#### 4.2.4 Merging the parameters
Finally we merged the cut-off standard deviation values of the players with their respective Twitter-account data, including the count of followers, the count of posted statuses, the count of accounts indicated as favorites and the players' screen name. Now the last step was to create a final set of players we wanted to consider in our analysis by merging the two data sets created into one and picking the top intersecting players.

```{r display_relevant_players, eval = TRUE, message = TRUE}
relevant_players %>%
  head(100)
```

```{r select_relevant_player_stats, eval = TRUE}
relevant_player_stats <- relevant_players %>% 
  inner_join(player_game_stats) %>% 
  filter(! is.na(MP)) %>% 
  inner_join(game_metadata) %>% 
  filter(Season %in% c("2017-18", "2018-19"))
```

```{r display_relevant_player_stats, eval = TRUE, message = TRUE}
relevant_player_stats %>%
  head(100)
```

### 4.3 Extracting the relevant tweets
With the given data we were now able to extract exactly those tweets we needed for our analysis. To do so, we chose to use the get_all_tweets function from the `academictwitteR` package.

To only extract tweets that can be assumed to be relevant for a specific game day, we delimited the time range of tweets to be considered for the extraction to the time between 24 hours and 45 minutes before a game (to be on the safe side, we first extracted tweets in a range of 48 hours before a game and boiled it down to 24 hours in an extra step). With the first limit we wanted to avoid that tweets, related to another match, get considered as it is not unusual that one player has two games in two days. The 45 minute delimiter was set according to the assumption, that it is unlikely for players to check their Twitter-account just 45 minutes before a game (It is even forbidden to players to look on their phones 15 minutes before a game). 
After these parameters were set, we obtained the tweets for each player of our preselection-list discussed before. Alongside with the raw text, the datetime of creation, the count how often a post was retweeted, the reply count, the favorite count and the quote count were added to the dataset of each players' tweets. A very important step for our later analysis was to map each tweet to the respective BBRef_Player_ID and the BBRef_Game_ID, to be able to address tweets based on a player- or a game-selection. Finally, each set got stored under the players' twitter name.

```{r extract_and_save_tweets, eval = FALSE}
#Attention! We set the extract_and_save_tweets code snippet on hold to sace processing effort and to not load millions of tweets for each rendering
#Attention!
time_window <- 48
tweet_cols <- c("BBRef_Player_ID", "BBRef_Game_ID", "id", "text", "created_at", "retweet_count", "reply_count", "like_count", "quote_count")
alrdy_proc_plyrs <- list.files(tweets_dir) %>% map_chr(~ str_remove(.x, "\\.csv$"))


relevant_player_stats %>% 
  filter(! Twitter %in% c(alrdy_proc_plyrs)) %>% 
  mutate(EndTweet = DateTime - lubridate::dminutes(45)) %>% 
  mutate(StartTweet = EndTweet - lubridate::dhours(time_window)) %>% 
  
  # Save tweets player-wise
  group_by(BBRef_Player_ID) %>% 
  group_walk(~ {
    tweets <- .x %>% pmap_dfr(function(...) {
      player_game_data <- tibble(...)
      
      start_tweets = player_game_data$StartTweet %>% iso8601() %>% paste0("Z")
      end_tweets = player_game_data$EndTweet %>% iso8601() %>% paste0("Z")
      
      twts <- tibble()
      
      tryCatch({
          twts <- get_all_tweets(
            query = player_game_data$Twitter,
            start_tweets = start_tweets,
            end_tweets = end_tweets,
            is_retweet = FALSE,
            lang = "en",
            bearer_token = twitter_bearer_token
          ) %>% 
            mutate(BBRef_Player_ID = player_game_data$BBRef_Player_ID) %>% 
            mutate(BBRef_Game_ID = player_game_data$BBRef_Game_ID)
        }, error = function(e) {
          # For Status Code 503
          print("Error loading tweets for the following game: ")
          print(player_game_data %>% select(c(Twitter, BBRef_Game_ID, DateTime, StartTweet, EndTweet)))
        }, finally = {
          return(twts)
        }
      )
      
    }) %>% 
      mutate(retweet_count = public_metrics$retweet_count) %>% 
      mutate(reply_count = public_metrics$reply_count) %>% 
      mutate(like_count = public_metrics$like_count) %>% 
      mutate(quote_count = public_metrics$quote_count) %>% 
      select(tweet_cols)
    
    file_name <- .x$Twitter %>% unique() %>% paste0(".csv")
    file_path <- tweets_dir %>% paste(file_name, sep = "/")
    
    tweets %>% write_csv(file_path)
  })
```

```{r load_tweets_1, eval = TRUE}
tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

tweets <- player_metadata %>% inner_join(tweets)
```

```{r display_tweets, eval = TRUE, message = TRUE}
tweets %>%
  head(100)
```

## 5. Pre-processing the Twitter Data
After we finished setting up our datasets and before extracting sentiments from the tweets it was reasonable to pre-process them in order to improve the accuracy of the computed sentiments, especially for our case where the text was in the form of tweets. Tweets are often written in a less formal language, including abbreviations and slang, so our focus laid in identifying and converting these phenomenons into a language that has increased machine readability. That is why we used the `textclean` package to apply the following pre-processing steps on each tweet: 

At first, each tweet got lowercased. Then we resolved non-ascii characters, replaced html-symbols by word meanings (e.g. "&amp" to "and") so that they can be captured by the analyzer and replaced (multiple succeeding) white space symbols by single white spaces (e.g. "\\t" by " "). After that, Twitter mentions, hashtags as well as URLs (e.g. "@StephenCurry30", "#BBNFOREVER", "https://t.co/37cSfQhMJs") got removed as they give us no further information about the sentiments and only force the analyzer to run over more words to check in the lexicon. Additionally we replaced emojis by their word meaning (e.g. ":)" to "smiley"). Similar to how we treated html-symbols, contractions got replaced by their multi-word forms (e.g. "I'll" to "I will") again for the sake of machine readability. 
We replaced common words, which letters were written with spaces in between (for emphasis), by their semantic equivalent without spaces (e.g. "B O M B" to "BOMB") and replaced word lengthening to emphasize or alter word meanings by their semantic equivalent (e.g. "niiiice" to "nice"). Finally, internet slang and abbreviations got replaced by their semantic equivalent (e.g. "YOLO" to "you only live once").

A very important decision that should be noted is, that stemming (i.e. Porter Stemming) was not applied to the tweets since the terms are written in their base form in the sentiment lexica. Additionally stopword-removal was not performed to avoid the risk of removing potentially crucial valence shifters for the sentiment extraction (e.g. in "I am **not** happy" the term "**not**" negates the sentiment and should therefore not be removed). These valence shifters will play a significant role in the sentiment analyzer we chose to work on our data and we will get back to this in a later section.

```{r load_tweets_2, eval = TRUE}
tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv) %>% 
  select(c(id, text)) %>% 
  
  # Eliminate duplicate tweets (addressed to multiple players) to accelerate processing
  unique() 
```

```{r preprocess_tweets}
prep_tweets <- tweets %>% 
  mutate(prep_text = imap_chr(tweets$text, ~{
    
    print(.y %>% paste(nrow(tweets), sep = "/"))
      
    # Replace words which letters are written with spaces in between for emphasis by their semantic equivalence (e.g. "B O M B" -> "BOMB")
    txt <- replace_kern(.x)
    
    # Replace emoji by description
    txt <- replace_emoji(txt)
    
    # Replace non-ascii characters by semantic equivalent
    txt <- replace_non_ascii(txt)
    
    # Replace contractions by their multi-word forms (e.g. "I'll" -> "I will")
    txt <- replace_contraction(txt)
    
    # Text to lowercase 
    txt <- str_to_lower(txt)
    
    # Remove Twitter URL's, mentions and hashtags
    txt <- replace_url(txt) 
    txt <- replace_tag(txt)
    txt <- replace_hash(txt)
    
    # Replace html symbols by semantic equivalent symbol (e.g. "&amp;" -> "and")
    txt <- replace_html(txt)
    txt <- replace_symbol(txt)
    
    # Replace word lenghenings to emphasize or alter word meanings by their semantic equivalence (e.g. "I said heyyy!" -> "I said hey sexy!")
    txt <- replace_word_elongation(txt, impart.meaning = TRUE) 
    
    # Replace internet slang by their semantic equivalence (e.g. "YOLO" -> "You only live once")
    txt <- replace_internet_slang(txt)
    
    # Replace white space characters by single white space and trim
    txt <- replace_white(txt)
    txt <- str_trim(txt)
    
  }))
  
```

One of the first issues we were confronted with when we started looking into our extracted Twitter data and ran a sentiment analysis on it, was that emojis didn't get processed properly by any analyzer we tested. But in our opinion, no component of a tweet carries emotions so strongly than these emojis (which of course already gets implied by the name). So, besides the pre-processing of the textual information of the tweets themselves, we decided to additionally handle emojis separately by letting a special emoji-analyzer, the **_Novak_** Emoji Sentiment Lexicon, run over them. They were extracted from each tweet and stored by their key representation (from the **_Novak_** Emoji Sentiment Lexicon) in a separate variable separated by white spaces in order to use them for an encapsulated emoji sentiment computation for the individual tweets.

```{r extract_emojis}
emoji_sentiment_lexicon <- lexicon::hash_sentiment_emojis %>% tibble()
emoji_regex <- emoji_sentiment_lexicon$x %>% paste(collapse = "|")

prep_tweets <- prep_tweets %>% 
  mutate(emojis = map_chr(tweets$text, ~ {
    .x %>% 
      replace_emoji_identifier() %>% 
      str_extract_all(emoji_regex) %>% 
      unlist() %>% 
      paste(collapse = " ")
  }))
```

```{r store_preprocessed_tweets}
file_path <- data_dir %>% paste("prep-tweets.csv", sep = "/")

prep_tweets %>% 
  select(c(id, prep_text, emojis)) %>% 
  write_csv(file_path)
```

```{r load_preprocessed_tweets, eval = TRUE}
prep_tweets <-data_dir %>% 
  paste("prep-tweets.csv", sep = "/") %>% 
  read_csv()
```

The following table gives an idea about how the tweets look like before and after the performed pre-processing steps: 

```{r display_preprocessed_tweets, eval = TRUE}
tweets %>%
  inner_join(prep_tweets) %>% 
  select(c(text, prep_text, emojis)) %>% 
  unique() %>%
  head(100)
```

## 6. Sentiment Extraction
Our next task was to extract sentiments from the pre-processed tweets and extracted emojis. To solve this task we used the package `sentimentr`, since compared to other solutions (e.g. `syuzhet` and `tidytext`), `sentimentr` uses an ordered bag of words model that allows it to incorporate valance shifters before or after polarized words to negate or intensify their sentiment (e.g. "I do **not** like it!" or "I **really** like it!"). That ultimately gives `sentimentr` the power to much more accurately assign sentiments to text passages. 

The sentiments were computed sentence-wise for each tweet and aggregated via the ``average_downweighted_zero`` ``sentimentr``-function that downweights sentiment-scores for sentences close to zero. 

The following sentiment lexica were used to compute the sentiments for each tweet by making use of the `lexicon` package: 

* **_Bing_**: positive/negative word list created by Hu Xu and Bing Liu (TODO reference).
* **_Syuzhet_**: word list with sentiment scores reaching from -1 to 1 created by Matthew L. Jockers (TODO reference).
* **_Jockers-Rinker_**: combined version of the Jocker's **_Syuzhet_** lexicon and Rinker's augmented **_Bing_** lexicon (TODO reference).
* **_NRC_**: positive/negative word list created by Saif M. Mohammad (TODO reference).
* **_AFINN_**: word list with sentiments reaching on a discrete scale from -5 to 5 created by Finn Årup Nielsen (TODO reference).
* **_Novak_**: list of emojis with sentiment scores reaching from -1 to 1 created by Kralji Novak (TODO reference http://kt.ijs.si/data/Emoji_sentiment_ranking/index.html). It should be noted that this sentiment lexicon was only applied on the extracted emojis but not on the text of the pre-processed tweets. Furthermore tweets that contained no emojis were excluded from the sentiment computation. 

```{r load_tweets_3, eval = TRUE}
tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

prep_tweets <- data_dir %>% paste("prep-tweets.csv", sep = "/") %>% read_csv()

# tweets %>% inner_join(prep_tweets) %>% select(c(text, prep_text, emojis))
```

```{r bing_sentiments}
bing_sentiments <- prep_tweets %>% 
  mutate(sentences = get_sentences(prep_text)) %$%
  sentiment_by(sentences, list(id), polarity_dt = lexicon::hash_sentiment_huliu) %>% 
  tibble()

file_path <- sentiments_dir %>% paste("bing.csv", sep = "/")
bing_sentiments %>% write_csv(file_path)

bing_sentiments
```

```{r syuzhet_sentiments}
syuzhet_sentiments <- prep_tweets %>% 
  mutate(sentences = get_sentences(prep_text)) %$%
  sentiment_by(sentences, list(id), polarity_dt = lexicon::hash_sentiment_jockers) %>% 
  tibble()

file_path <- sentiments_dir %>% paste("syuzhet.csv", sep = "/")
syuzhet_sentiments %>% write_csv(file_path)

syuzhet_sentiments
```

```{r jockers_rinker_sentiments}
jockers_rinker_sentiments <- prep_tweets %>%
  mutate(sentences = get_sentences(prep_text)) %$%  
  sentiment_by(sentences, list(id)) %>% 
  tibble()

file_path <- sentiments_dir %>% paste("jockers-rinker.csv", sep = "/", polarity_dt = lexicon::hash_sentiment_jockers_rinker)
jockers_rinker_sentiments %>% write_csv(file_path)

jockers_rinker_sentiments
```

```{r nrc_sentients}
nrc_sentiments <- prep_tweets %>% 
  mutate(sentences = get_sentences(prep_text)) %$%
  sentiment_by(sentences, list(id), polarity_dt = lexicon::hash_sentiment_nrc) %>% 
  tibble()

file_path <- sentiments_dir %>% paste("nrc.csv", sep = "/")
nrc_sentiments %>% write_csv(file_path)

nrc_sentiments
```

```{r afinn_sentiments}
# Note: download for "afinn" has to be confirmed
hash_sentiment_afinn <- tidytext::get_sentiments("afinn") %>% 
  rename(c(x = word, y = value)) %>% 
  as_key() # convert tibble to data table for sentimentr

afinn_sentiments <- prep_tweets %>% 
  mutate(sentences = get_sentences(prep_text)) %$%
  sentiment_by(sentences, list(id), polarity_dt = hash_sentiment_afinn) %>% 
  tibble()

file_path <- sentiments_dir %>% paste("afinn.csv", sep = "/")
afinn_sentiments %>% write_csv(file_path)

afinn_sentiments
```

```{r novak_emoji_sentiments}
novak_emoji_sentiments <- prep_tweets %>%
  filter(emojis != "") %>% 
  filter(! is.na(emojis)) %>%
  mutate(emojis = replace_emoji_identifier(emojis)) %>% 
  mutate(sentences = get_sentences(emojis)) %$%
  sentiment_by(sentences, list(id), polarity_dt = lexicon::hash_sentiment_emojis) %>% 
  tibble() 

file_path <- sentiments_dir %>% paste("novak-emoji.csv", sep = "/")
novak_emoji_sentiments %>% write_csv(file_path)

novak_emoji_sentiments 
```

## 7. Exploratory Data Analysis

```{r load_nba_stats, eval = TRUE}
player_metadata <- paste(data_dir,"player-metadata.csv", sep ="/") %>% read_csv()
player_game_stats <- paste(data_dir,"player-game-stats.csv", sep ="/") %>% read_csv()
game_metadata <- paste(data_dir,"game-metadata.csv", sep ="/") %>% read_csv()
player_season_stats <- paste(data_dir,"player-season-stats.csv", sep ="/") %>% read_csv()
```


```{r load_tweets, eval = TRUE}
tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

prep_tweets <- data_dir %>% 
  paste("prep-tweets.csv", sep = "/") %>% 
  read_csv()
```


```{r load_sentiments, eval = TRUE}
sentiment_names <- c("bing", "syuzhet", "jockers_rinker", "afinn", "nrc", "novak_emoji")

sentiments <- sentiment_names %>% 
  map_dfr(~ {
    sentiment_name <- .x
    
    sentiment_file <- sentiments_dir %>% 
      paste(sentiment_name, sep = "/") %>% 
      paste0(".csv") %>% 
      str_replace("_", "-")
    
    sentiments_tmp <- read_csv(sentiment_file) %>% 
      mutate(positive_sentiment = if_else(ave_sentiment >= 0, TRUE, FALSE)) %>% 
      mutate(sentiment_lexicon = sentiment_name)
      
  })
```

### 7.1 Comparability of the Sentiment Lexicons

In the beginning we wanted to assess if the sentiment scores the different sentiment lexica provided for tweets were actually comparable. For that purpose we computed the Spearman rank correlation coefficient between tweet sentiment scores provided by each pair of sentiment lexicons to assess whether the ranking of the tweets according to one sentiment lexicon agrees with the ranking of the tweets according to another sentiment lexicon. 

```{r compute_sentiment_consensus_spearman, eval = TRUE}
sentiment_lexicons <- sentiments$sentiment_lexicon %>% unique()

# Create cross product of sentiment_lexicon with itself
sentiment_lexicons_a <- sentiment_lexicons %>% 
  rep(each = length(sentiment_lexicons))
sentiment_lexicons_b <- sentiment_lexicons %>% 
  rep(times = length(sentiment_lexicons))

# For each pair of sentiment lexicons compute Kendall rank correlation coefficient
sentiment_lexicon_consensus <- map2_dfr(sentiment_lexicons_a, sentiment_lexicons_b, ~ {
  
  sentiments_a <- sentiments %>% 
    filter(sentiment_lexicon == .x) %>% 
    mutate(ave_sentiment_a = ave_sentiment) %>% 
    select(id, ave_sentiment_a) 
  
  sentiments_b <- sentiments %>% 
    filter(sentiment_lexicon == .y) %>%
    mutate(ave_sentiment_b = ave_sentiment) %>% 
    select(id, ave_sentiment_b)
  
  inner_join(sentiments_a, sentiments_b) %>% 
    mutate(sentiment_lexicon_a = .x) %>% 
    mutate(sentiment_lexicon_b = .y) %>%  
    group_by(sentiment_lexicon_a, sentiment_lexicon_b) %>% 
    summarise(consensus = cor(ave_sentiment_a, ave_sentiment_b, method = "spearman", use = "complete.obs")) %>% 
    ungroup()
  
})
```

We then plotted the results into a heatmap:

```{r plot_sentiment_consensus, eval = TRUE, fig.width = 10}
sentiment_lexicon_consensus %>% 
  ggplot(mapping = aes(x = sentiment_lexicon_a, y = sentiment_lexicon_b)) +
    geom_tile(mapping = aes(fill = consensus)) +
    geom_text(mapping = aes(label = round(consensus, 3))) +
    scale_fill_gradient(low = "white", high = "red") + 
    labs(
      title = "Consensus of the Sentiment Lexicons in giving Sentiment\nScores to Tweets addressed to NBA Basketball Players", 
      subtitle = "Using the Spearman Rank Correlation Coefficient"
    ) +
    theme_minimal() + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.x = element_blank(),
      axis.title.y = element_blank()
    ) 
```

Generally we can see that except of the Emoji Sentiment Lexicon by Novak all other sentiment lexicons seem to correlate rather well. Apparently the computed tweet sentiments from the Emoji Lexicon differ strongly from the sentiments of the other lexicons which is reasonable since the Emoji Lexicon is only computed on the emojis contained in the tweet while the other lexicons use the textual information of the tweet. The Jockers Rinker and Syuzhet lexicons are most similar with a Spearman correlation coefficient around 0.95. This intuitively also makes sense since Jockers-Rinker is a combined version of Syuzhet and Bing as mentioned before.

### 7.2 Computing Sentiment Aggregates

Since the sentiment scores were computed on a per-tweet basis we first had to aggregate the sentiment scores accordingly in order to capture the overall social media vibe players were receiving before games in a single number. For that purpose we considered the sentiment scores of all tweets a respective player received in a 24 hour window before a respective game and aggregated them as follows:  

* The average of the sentiment scores (mean). 
* The average of the sentiment scores weighted by the retweet count of the associated tweet (weighted mean). 
* The proportion of tweets with a negative associated sentiment score (< 0).


```{r compute_sentiment_aggregates_24h_before_games, eval = TRUE}
tweets_24h_before_games <- player_game_stats %>%
  inner_join(game_metadata) %>% 
  inner_join(tweets) %>% 
  mutate(h_timediff_game = as.double(DateTime - created_at, units = "hours")) %>% 
  select(c(names(tweets), h_timediff_game))  %>%
  filter(h_timediff_game <= 24)

sentiment_aggregates_24h_before_games <- tweets_24h_before_games %>% 
  inner_join(sentiments) %>% 
  group_by(BBRef_Player_ID, BBRef_Game_ID, sentiment_lexicon) %>% 
  summarise(
    avg_sentiment = mean(ave_sentiment),
    avg_sentiment_retweet_cnt_weighted = weighted.mean(ave_sentiment, retweet_count),
    rel_freq_negative = sum(!positive_sentiment) / n()
  ) 
```

The following table shows an excerpt of the per-game computed sentiment aggregates for the different sentiment lexica: 

```{r display_sentiment_aggregates_24h_before_games, eval = TRUE, message = TRUE}
sentiment_aggregates_24h_before_games
```

### 7.3 Univariate Distribution Analysis

At this point we had all the necessary data to analyze the association between the aggregated sentiment scores of tweets the players received within 24 hours before games and their performance within the games. 

Before analyzing these bivariate relationships however we first wanted to get a general idea how the individual variables were distributed. 

#### 7.3.1 Distribution of the Sentiment Aggregates

Plotting the density curves for the unweighted average sentiment scores for the different sentiment lexica and players revealed the following picture: 

```{r plot_density_curves_avg_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment)) +
    geom_density() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Density Plots of the Average Sentiments of Tweets Players were receiving within 24 Hours before Games", 
      subtitle = "For different Players and Sentiment Lexicons between the seasons 2017-18 and 2018-19", 
      x = "Average Tweet Sentiment", 
      y = "Density"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Looking at the individual density curves we observed that the distributions of the average sentiment scores roughly fit the bell curve of a Normal distribution despite a few exceptions (esp. for the averaged sentiments for the emoji sentiment lexicon by Novak). 

To check our normality assumption we also constructed Q-Q plots for the unweighted average sentiment scores: 

```{r plot_qq_plot_avg_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(sample = avg_sentiment)) + 
    geom_qq(alpha = 0.2) + 
    geom_qq_line() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Average Sentiments of Tweets Players were receiving within 24 Hours before Games", 
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

The Q-Q plots confirmed our assumption of normality, since despite some curve offs at the extremities (some observed extremes were more extreme than expected), most of the observed quantiles matched the expected quantiles of the fitted Normal distribution. 

A similar picture could be observed for the average weighted sentiment scores (weighted by their associated retweet count) as the following equivalent grid of Q-Q plots shows:

```{r plot_qq_plot_avg_weighted_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(sample = avg_sentiment_retweet_cnt_weighted)) + 
    geom_qq(alpha = 0.2) + 
    geom_qq_line() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Average Sentiments of Tweets Players were\nreceiving within 24 Hours before Games weighted by their Retweet Count", 
      subtitle = "For different Players and Sentiment Lexicons between the Seasons  2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    ) 
```

The distributions for the negative tweet proportions mostly did not follow a Normal distribution and were strongly right skewed however. That intuitively made sense since in most of the cases players only received a small proportion of tweets with a negative sentiment which leads to the right skewness of the distribution (also because proportions cannot go below 0). The following grid of density plots emphasize that circumstance:

```{r plot_density_curves_weighted_rel_freq_negative, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = rel_freq_negative)) +
    geom_density() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free")+ 
    labs(
      title = "Density Plots of the Proportion of Tweets with a negative Sentiment Players were receiving within 24 Hours before Games",
      subtitle = "For different Players and Sentiments Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Proportion of Negative Tweets", 
      y = "Density"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

#### 7.3.2 Distribution of the Box Plus/Minus Performance Indicator

Besides the sentiment aggregates we also studied how the BPM performance indicator values are distributed for the different players. Similar to the unweighted and weighted sentiment averages before, BPM was also normally distributed as the following grid of Q-Q plots indicates: 

```{r plot_qq_plot_BPM, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  mutate(variable = "BPM") %>% 
  distinct(Player, BBRef_Game_ID, BPM, variable) %>% 
  ggplot(mapping = aes(sample = BPM)) + 
    geom_qq(alpha = 0.4) + 
    geom_qq_line() + 
    facet_grid(Player ~ variable, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Box Plus/Minus (BPM) Performance Indicator",
      subtitle = "For different Players between the Seasons 2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Knowing that the BPM values were normally distributed for the different players it was sufficient to simply construct boxplots for the performance indicator to get a sense how the individual players performed in general and how their performance fluctuated over the two considered seasons. 

```{r plot-boxplot-BPM, eval = TRUE, fig.width = 10}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  distinct(Player, BBRef_Game_ID, BPM) %>% 
  ggplot(mapping = aes(x = reorder(Player, BPM, na.rm = TRUE), y = BPM)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(
      title = "Boxplots of the Box Plus/Minus (BPM) Performance Indicator",
      subtitle = "For different Players between the Seasons 2017-18 and 2018-19", 
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.y = element_blank()
    ) 
```

### 7.4 Bivariate Distribution and Correlation Analysis

After having observed the univariate distributions of the variables that were of importance for this analysis, we now wanted to assess whether there is a relationship between the individual sentiment aggregates and the BPM values for any of the individual players and sentiment lexicons. 

#### 7.4.1 Relationship between the Average 24-Hour Tweet Sentiment and the BPM Performance Indicator

We began by having a closer look at the relationship between the unweighted sentiment average and the BPM performance indicator. For that purpose we created a grid of scatterplots for each player and sentiment lexicon combination and fitted a simple linear regression line through each of the resulting point clouds. Additionally, to measure the strength and direction of a potential bivariate linear relationships, we made use of the `ggpubr`-library by adding the corresponding Pearson correlation coefficient *r* and its associated *p*-value (using a T-test statistic with n-2 degrees of freedom) to each scatterplot. It should be noted here that the Pearson correlation coefficient was applicable since both variables were normally distributed as indicated before. Furthermore, we added the *p*-value to measure how significant the corresponding Pearson correlation coefficient deviated from zero (no correlation / linear relationship). The resulting plot is represented below.

```{r plot_relationship_avg_sentiments_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "pearson", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Average Sentiment of Tweets Players received\nwithin 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Average Tweet Sentiment",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

As one can see, the points of the different scatterplots appeared rather scattered and for the different sentiment lexicons and players there was neither a strong nor direclty visible (linear) relationship between the average tweet sentiment and the BPM performance indicator. Even though some of the linear regression lines suggested a correlation, the correlations themselves were rather weak or even neglectable as indicated by the respective Pearson correlation coefficients *r* that were relatively small (mostly less than 0.1). Additionally most of the *p*-values of the associated Pearson correlation coefficients were rather high which suggested that the observed strength of the correlations were not significantly different from 0 (and might have appeared due to random chance). 

Nevertheless, there were also some counter examples where the Pearson correlation coefficient appeared rather significant. The player Jaylen Brown for example showed a positive correlation for the Afinn lexicon with a *p*-value below 0.05. However, since the correlations were rather weak, not significant and somehow contradicting for other sentiment lexicons (compare that the correlation was negative for the nrc lexicon), it is debatable if the positive correlation is generalizable for the entire population or even the single player alone. 

Due to these reasons we had to conclude that there is no evidence of a significantly strong linear correlation between the average sentiment of tweets players receive within 24 hours before games and their performance within the games. 

There was however another interesting observation the scatterplots revealed, namely the prominent outliers. For almost every player there was at least one game day in which the average tweet sentiment was vastly more positive compared to other days. Additionally there were some players with game days associated with an extremely negative average tweet sentiment in comparison to other days. To investigate these outliers more closely we created two word clouds for each player, one for the worst average tweet sentiment the player received and one for the best. We used the tweet sentiments created from the Jockers-Rinker lexicon for this purpose and mapped the 50 most frequent words that appeared in the corresponding tweets on each wordcloud. 

```{r compute_rel_word_frequencies_extreme_sentiments, eval = TRUE}
worst_sentiments <- sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, - avg_sentiment) %>% 
  mutate(extreme_type = "Worst Sentiment")

best_sentiments <- sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, avg_sentiment) %>% 
  mutate(extreme_type = "Best Sentiment")

word_frequencies <- bind_rows(worst_sentiments, best_sentiments) %>% 
  inner_join(player_metadata) %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  mutate(prep_text = str_remove_all(prep_text, "[:digit:]")) %>% 
  drop_na(prep_text) %>% 
  group_by(Player, extreme_type) %>% 
  unnest_tokens(word, prep_text) %>% 
  anti_join(stop_words) %>%
  group_by(Player, extreme_type, word) %>% 
  summarise(freq = n()) 

rel_word_frequencies <- word_frequencies %>% 
  group_by(Player, extreme_type) %>% 
  summarise(total = sum(freq)) %>% 
  inner_join(word_frequencies) %>% 
  mutate(rel_freq = freq / total)
```


```{r plot_word_clouds_extreme_sentiments, eval = TRUE, fig.width = 10, fig.height = 35}
rel_word_frequencies %>% 
  
  # Min/Max-Scaling for visibility 
  group_by(Player, extreme_type) %>% 
  summarise(max_rel_freq = max(rel_freq), min_rel_freq = min(rel_freq) ) %>% 
  inner_join(rel_word_frequencies) %>% 
  mutate(rel_freq_scaled = (rel_freq - min_rel_freq) / (max_rel_freq - min_rel_freq) + 1) %>% 
  
  # Used for diverging color scale
  mutate(
    rel_freq_color = if_else(
      extreme_type == "Worst Sentiment", 
      (-1) * rel_freq_scaled,
      rel_freq_scaled
    )
  ) %>% 
  
  # To display higher frequency terms in the middle
  arrange(desc(rel_freq)) %>% 
  
  # Select top 50 of the highest frequent terms for the worst and best avg. sentiment of each player
  group_by(Player, extreme_type) %>%
  slice_head(n = 50) %>% 
  
  # Plot result
  ggplot(mapping = aes(label = word, size = rel_freq_scaled, color = rel_freq_color)) + 
    geom_text_wordcloud_area(rm_outside = TRUE) + 
    scale_size_area(max_size = 8) + 
    scale_color_gradient2(low = "blue", high = "red") +
    facet_grid(Player ~ extreme_type) +
    theme_minimal()
```

The most prominent observation derived from the wordclouds was that the best average sentiments were frequently associated with the words "happy" and "birthday", which indicated that these players were receiving birthday wishes on that same game day. Besides birthdays it appeared that other players received positive tweet sentiments due to another important day or event in their life. For Stephen Curry the terms "baby", "congrats", "boy", "family", "hands", "blue" and "eyes" occurred rather frequently. By having a glimpse on the tweets he received that day, we can see people were congratulating him for another baby that was on the way: 

```{r compute_best_sentiment_tweets_stephen_curry, eval = TRUE, message = TRUE}
best_sentiments %>% 
  inner_join(player_metadata) %>% 
  filter(Player == "Stephen Curry") %>%
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  select(prep_text)
```

For the worst sentiments the picture was not that clear on the other hand. Jamal Murray for example also frequently received the words "happy" and "birthday" on the game day with the worst average tweet sentiment. By a closer look on the tweets themselves however, we saw that he was only tagged on 22 tweets that day and that the birthday wishes were actually addressed to the player Dejuan Wagner, but not himself:

```{r display_worst_sentiment_tweets_jamal_murray, eval = TRUE, message = TRUE}
worst_sentiments %>% 
  inner_join(player_metadata) %>% 
  filter(Player == "Jamal Murray") %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  select(prep_text)
```

One noticeable observation was that swear words tended to appear more frequently in the associated tweets. E.g with regard to the worst sentiment game of Klay Thompson the terms "shots", "missed" and "bad", in combination with several swear words reflect a situation where the player received some hate due to some missed shots from a previous game. The example tweets are displayed below:

```{r display_worst_sentiment_tweets_klay_thompson, eval = TRUE}
worst_sentiments %>% 
  inner_join(player_metadata) %>% 
  filter(Player == "Klay Thompson") %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  filter(str_detect(prep_text, "bad|fucking|mad|fuck|fucking|missed")) %>% 
  select(prep_text)
```

Nevertheless it was hard to make a general conclusion why the players received such bad tweet sentiments on the associated days from the most frequent terms alone. 

#### 7.4.2 Relationship between the Weighted Average 24-Hour Tweet Sentiment and the BPM Performance Indicator

One might argue that players who receive over a thousand tweets each day, is not capable of reading or even noticing all the tweets he receives. Due to this we made the assumption, that those tweets, which have a higher retweet count also have a higher likelihood of being read. Considering this, we now used the retweet-count-weighted sentiments, which already got created before, for the computation of the the mean sentiment and created a correlation plot like we did in the previous section.

```{r plot_relationship_weighted_avg_sentiments_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment_retweet_cnt_weighted, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "pearson", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Retweet Count Weighted Average Sentiment of Tweets Players\nreceived within 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Retweet Count Weighted Average Tweet Sentiment",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Generally we can say that the weighted average sentiment also did not reveal any better correlation results. There were however also some exceptions. For Josh Richardson the Pearson correlation coefficients appeared to be rather significant with *p*-values less than 0.1 for the different sentiment lexica (except for the emoji lexicon by Novak). Despite the fact that these correlations were all positive for this player, they were still quite weak however, with a maximum Pearson correlation coefficient of 0.29 for the Jockers-Rinker sentiment lexicon. Additionally it is to say that this is an exception and does not alter the general observation.

#### 7.4.3 Relationship between the Proportion of Negative Tweets and the BPM Performance Indicator

We created the same plot a third time, but now only considering the proportion of negative tweets a player received at each respective game. Since the distributions of the negative proportions were heavily right skewed and not normally distributed, we used the Kendall-Tau rank correlation coefficient instead of the Pearson metric. 

```{r plot_relationship_rel_freq_negative_tweets_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = rel_freq_negative, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "kendall", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Proportion of Tweets with a Negative Sentiment Players\nreceived within 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Relative Frequency of Negative Tweets",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Unfortunately, this aggregate delivered a similar picture regarding the correlation we wanted to inspect.

#### 7.4.4 Time Dependent Relationship between the Average Tweet Sentiments and the BPM Performance Indicator

Finally, we investigated if there is maybe a time dependent relationship between the average sentiment score and the BPM value the players received. For that purpose we exemplary plotted the Jockers-Rinker average sentiments and the BPM values against the game dates on which they were observed for each player for the season 2018-19. Since both variables fluctuated quite strongly over the considered timespan we overlaid a smoothed average line to improve the interpretation ability. The resulting plot is displayed below. 

```{r season_18_19_trend_BPM_vs_jockers_rinker, eval = TRUE, message = TRUE, fig.width = 10, fig.height = 80}
scaling_coef <- 60

player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  filter(SeasonType == "Regular Season") %>% 
  filter(Season %in% c("2018-19")) %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  rename(jockers_rinker = avg_sentiment) %>% 
  ggplot(mapping = aes(x = Date)) +
  
    geom_smooth(mapping = aes(y = BPM), se = FALSE, color = "blue") + 
    geom_line(mapping = aes(y = BPM), color = "blue", alpha = 0.2) + 
  
    geom_smooth(mapping = aes(y = jockers_rinker * scaling_coef), se = FALSE, color = "red") +
    geom_line(mapping = aes(y = jockers_rinker * scaling_coef), color = "red", alpha = 0.2) + 
  
    facet_wrap(~ Player, ncol = 1) +
  
    scale_y_continuous( 
      name = "Box Plus/Minus (BPM)",
      sec.axis = sec_axis(~./scaling_coef, name = "Jockers-Rinker Sentiment Average")
    ) + 
    coord_cartesian(ylim = c(-10,20)) + 
    labs(
      title = "Time-Dependent Relationship between the Average Sentiments of Tweets Players received\nwithin 24 Hours before Games and their BPM Value within the Games in the season 2018-19", 
      subtitle = "Using the Jockers-Rinker Sentiment Average"
    ) +
    theme_minimal() + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.y = element_text(color = "blue"),
      axis.title.y.right = element_text(color = "red")
    )
```

As one can see, there appeared to be also no time-dependent association between the variables.

Concluding to this section we can wrap up our observations as follows:

 * The desired positive correlation between the average sentiments of tweets related to one specific player and game could not be found with any of the approaches described.
 * Therefore, based on our analyses, it is to assume that our main hypothesis does not hold true and there is no significant correlation between these two variables.

## 8. Predictive Model
One attempt to check whether the sentiments have an influence on the players' performance at all and therefore to investigate our findings in the correlation analysis, was to set up a random forest regression model to predict the BPM of players. The idea was to set up different models and compare the predictions with and without the sentiments as input features. We set up the following models:

 - mean BPM of the last 5 BPMs as a baseline model
 - model including only the sentiment scores
 - model including the last 5 BPMs, Position, Age, Month of the Game, Homegame, Trend, SRS_Team, SRS_Opponent
 - model including the last 5 BPMs, Position, Age, Month of the Game, Homegame, Trend, SRS_Team, SRS_Opponent and the sentiment scores
 
In detail, Homegame expresses whether the player played a homegame (1) or an away game (0). The Trend indicates the teams last 5 game performances - i.e. the sum of wins (+1) and losses (-1) is calculated. In order to measure a more longterm team performance we used the SRS (Simple Rating System) which gives a score to each team according to their average point difference and strength of schedule and where 0 marks the average score. The SRS for the previous season was used for the prediction.

We started by loading the tweets and extracted the necessary columns before transforming them. 

```{r load_tweets_and_transform, message = FALSE, eval = TRUE, echo = FALSE}
data_dir <- "../data"
sentiments_dir <- "../data/sentiments"
tweets_dir <- data_dir %>% paste("tweets", sep = "/")

tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

player_game_stats <- data_dir %>% paste("player-game-stats.csv", sep = "/") %>% read_csv()
player_season_stats <- data_dir %>% paste("player-season-stats.csv", sep = "/") %>% read_csv()

games <- tweets %>% 
  select(BBRef_Player_ID ,BBRef_Game_ID) %>%
  unique() %>%
  left_join(player_game_stats %>% select(BBRef_Player_ID,BBRef_Game_ID,Season, Date, Tm, HTm, Opp, WL,BPM), by = c("BBRef_Player_ID" = "BBRef_Player_ID", "BBRef_Game_ID" = "BBRef_Game_ID")) %>%
  left_join(player_season_stats %>% select(BBRef_Player_ID,Season, Age, Pos), by = c("BBRef_Player_ID" = "BBRef_Player_ID", "Season" = "Season")) %>%
  unique()

player_game_stats <- player_game_stats %>%
  mutate(index = 1:nrow(player_game_stats)) %>% # get an index in order to use for the last 5 BPMs
  mutate(WL_ = ifelse(str_detect(player_game_stats$WL, "W"),1,-1)) # use for trend variable

games <- games %>%
  mutate(Homegame = ifelse(games$Tm == games$HTm,1,0)) %>%
  mutate(Month = month(Date))

get_BPM_Trend <- function(player, game){
  index <- player_game_stats %>%
    filter(BBRef_Player_ID == player,BBRef_Game_ID == game) %>%
    select(index) %>%
    pull()
  
  games <- games %>%
    filter(BBRef_Player_ID == player,BBRef_Game_ID == game) %>%
    mutate(BPM_5 = player_game_stats$BPM[index-5]) %>%
    mutate(BPM_4 = player_game_stats$BPM[index-4]) %>%
    mutate(BPM_3 = player_game_stats$BPM[index-3]) %>%
    mutate(BPM_2 = player_game_stats$BPM[index-2]) %>%
    mutate(BPM_1 = player_game_stats$BPM[index-1]) %>%
    mutate(Trend = sum(player_game_stats$WL_[(index-5):(index-1)]))
}

games <- map2_dfr(games$BBRef_Player_ID, games$BBRef_Game_ID, ~ get_BPM_Trend(.x, .y)) # get the last 5 BPMs and Trend for each player/game combination
```

After that the SRS (Simple Rating System) for the previous season are extracted. This was done by parsing the html table from [basketball-reference.com](https://basketball-reference.com) and using the teams shortcut to combine the data with the previous dataset.

```{r load_basketball_reference_data, message = FALSE, eval = TRUE, echo = FALSE}
content <- read_html("https://www.basketball-reference.com/leagues/NBA_2018.html")
tables <- content %>% html_table(fill = TRUE)
team_stats_2018 <- tables[[11]]

team_stats_2018 <- team_stats_2018[,c(2,10)] %>% 
  tail(-1) %>% 
  head(-1) %>%
  setNames(c("Team","SRS")) %>%
  mutate(SRS = as.double(SRS)) %>%
  mutate(Team_name = c("HOU","TOR","GSW","UTA","PHI","BOS","OKC","SAS","POR","MIN","DEN","IND","NOP","CLE","WAS","MIA","CHO","LAC","DET","MIL","LAL","DAL","NYK","BRK","ORL","ATL","MEM","CHI","SAC","PHO")) %>%
  mutate(Season_plus_one = "2018-19")

content <- read_html("https://www.basketball-reference.com/leagues/NBA_2017.html")
tables <- content %>% html_table(fill = TRUE)
team_stats_2017 <- tables[[11]]

team_stats_2017 <- team_stats_2017[,c(2,10)] %>% 
  tail(-1) %>% 
  head(-1) %>%
  setNames(c("Team","SRS")) %>%
  mutate(SRS = as.double(SRS)) %>%
  mutate(Team_name = c("GSW","SAS","HOU","TOR","LAC","UTA","CLE","BOS","WAS","MIA","OKC","MEM","DEN","CHI","CHO","IND","MIL","POR","ATL","DET","MIN","NOP","DAL","NYK","SAC","PHO","PHI","BRK","ORL","LAL")) %>%
  mutate(Season_plus_one = "2017-18")

team_stats <- rbind(team_stats_2017,team_stats_2018)

games <- games %>% 
  left_join(team_stats, by = c("Season" = "Season_plus_one", "Tm" = "Team_name")) %>%
  left_join(team_stats, by = c("Season" = "Season_plus_one", "Opp" = "Team_name"))
```

Then some of the variables got renamed and the mean BPM of the last 5 BPMs are calculated.

```{r rename_columns, message = FALSE, eval = TRUE, echo = FALSE}
data <- games %>%
  select(BBRef_Player_ID,BBRef_Game_ID,Age,Pos,BPM_5,BPM_4,BPM_3,BPM_2,BPM_1,Homegame, Month,SRS_Tm = SRS.x , SRS_Opp = SRS.y, BPM, Trend) %>%
  mutate(mean_BPM = rowMeans(games %>%select(BPM_5,BPM_4,BPM_3,BPM_2,BPM_1),na.rm = TRUE)) 
```

In the last pre-processing step, the already computed sentiments got merged with the newly created data.

```{r combine_sentiments_with_data, message = FALSE, eval = TRUE, echo = FALSE}
prep_tweets <- data_dir %>% paste("prep-tweets.csv", sep = "/") %>% read_csv()
bing <- sentiments_dir %>% 
  paste("bing.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, word_count, ave_sentiment)) %>% 
  rename(bing = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(bing < 0.0, "negative", "positive"))

syuzhet <- sentiments_dir %>% 
  paste("syuzhet.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(syuzhet = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(syuzhet < 0.0, "negative", "positive"))

jockers_rinker <- sentiments_dir %>% 
  paste("jockers-rinker.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(jockers_rinker = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(jockers_rinker < 0.0, "negative", "positive"))

afinn <- sentiments_dir %>% 
  paste("afinn.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(afinn = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(afinn < 0.0, "negative", "positive"))

nrc <- sentiments_dir %>% 
  paste("nrc.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(nrc = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(nrc < 0.0, "negative", "positive"))

novak_emoji <- sentiments_dir %>% 
  paste("novak-emoji.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(novak_emoji = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(novak_emoji < 0.0, "negative", "positive"))

sentiments <- tweets %>% 
  inner_join(prep_tweets) %>% 
  select(c(BBRef_Player_ID,BBRef_Game_ID,id, text, prep_text)) %>% 
  inner_join(bing) %>%
  inner_join(syuzhet) %>% 
  inner_join(jockers_rinker) %>% 
  inner_join(nrc) %>% 
  inner_join(afinn) %>% 
  inner_join(novak_emoji)

aggregated_sentiments <- sentiments %>% 
  group_by(BBRef_Player_ID, BBRef_Game_ID) %>% 
  summarize(bing = mean(bing), syuzhet = mean(syuzhet), jockers_rinker = mean(jockers_rinker), 
            nrc = mean(nrc), afinn = mean(afinn), novak_emoji = mean(novak_emoji))

data <- data %>% 
  left_join(aggregated_sentiments, by = c("BBRef_Player_ID" = "BBRef_Player_ID", "BBRef_Game_ID" = "BBRef_Game_ID"))


data <- data %>% drop_na(BPM,BPM_5,BPM_4,BPM_3,BPM_2,BPM_1,bing,syuzhet,jockers_rinker,nrc,afinn)
```

```{r plot_BPM, message = FALSE, eval = TRUE, echo = FALSE}
data %>%
  ggplot(aes(fct_reorder(BBRef_Player_ID,BPM), 
             BPM)) +
  geom_boxplot(outlier.alpha = 0.5) +
  coord_flip() +
  xlab("BPM performance") +
  ylab("BBRef_Player_ID")
```

For the actual prediction task we started by selecting the relevant columns for the model and split the data into training and testing data with a proportion of 75% training to 25% testing. A validation split of 20% of the training set was then performed in order to combat overfitting. Then each model was created using the recipe package. Using tune_grid(), the model parameter mtry (number of predictors that will be randomly sampled at each split when creating the tree models), trees (number of trees contained in the ensemble) and min_n (minimum number of data points in a node that are required for the node to be split further) are tuned. After tuning, we chose the best model fit based on the RMSE (Root Mean Square Error) which calculates the average distance between the predicted values and the actual values, i.e. the lower the RMSE, the better the model is able to fit a dataset. The importance score for each variable was saved as well.

```{r predictive_model, message = FALSE, eval = TRUE, echo = FALSE}
data <- data %>%
  select(Pos, Age, BPM_5, BPM_4, BPM_3, BPM_2, BPM_1, Homegame, Month, SRS_Tm, SRS_Opp, Trend, bing, syuzhet, jockers_rinker, nrc, afinn, novak_emoji, BPM, mean_BPM) %>% 
  drop_na(BPM,BPM_5,BPM_4,BPM_3,BPM_2,BPM_1,bing,syuzhet,jockers_rinker,nrc,afinn)

set.seed(123)
data_split <- initial_split(data)
data_train <- training(data_split)
data_test <- testing(data_split)
val_set <- validation_split(data_train, prop = 0.8)

# normal model
rf_rec <- recipe(BPM ~ BPM_5 + BPM_4 + BPM_3 + BPM_2 + BPM_1 + Pos + Age + Month + Homegame + Trend + SRS_Tm +  SRS_Opp, data = data_train) 

# model with sentiments
rf_rec_with_sentiment <- recipe(BPM ~ BPM_5 + BPM_4 + BPM_3 + BPM_2 + BPM_1 + Pos + Age + Month + Homegame + Trend + SRS_Tm +  SRS_Opp + bing + syuzhet + jockers_rinker + nrc + afinn + novak_emoji, data = data_train) 

# model with mean BPM
rf_rec_mean <- recipe(BPM ~ mean_BPM, data = data_train)

# model sentiments only
rf_rec_only_sentiment <- recipe(BPM ~ bing + syuzhet + jockers_rinker + nrc + afinn + novak_emoji, data = data_train)


get_model <- function(rec){
  rf_spec <- rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = tune()) %>%
  set_engine("ranger") %>%
  set_mode("regression")
  
  rf_wf <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(rec)  

  rf_res <- rf_wf %>%
  tune_grid(val_set,
            grid = 100,
            control = control_grid(save_pred = TRUE))  
  
  rf_best <- rf_res %>%
  select_best(metric = "rmse")
  
  last_rf_spec <- rand_forest(mtry = rf_best$mtry[1], min_n = rf_best$min_n[1], trees = rf_best$trees[1]) %>%
  set_engine("ranger", importance ="permutation") %>%
  set_mode("regression")

last_rf_wf <- rf_wf %>%
  update_model(last_rf_spec)

last_rf_fit <- last_rf_wf %>%
  last_fit(data_split)
}

model <- get_model(rf_rec)
model_with_sentiment <- get_model(rf_rec_with_sentiment)
model_mean_BPM <- get_model(rf_rec_mean)
model_only_sentiment <- get_model(rf_rec_only_sentiment)
```

In order to determine which model predicted the BPM performance best, a visualization is shown below that displays the predicted value (y-axis) and the true value (x-axis) for each model, meaning a perfectly fitted model would have all predictions on the the dashed line. The visualization doesn't allow for a clear interpretation since all models are scattered and no specific trend can be observed.

```{r predictions, message = FALSE, eval = TRUE, echo = FALSE}
predictions <- model$.predictions[[1]] %>%
  mutate(model = "without sentiments") %>%
  bind_rows(model_with_sentiment$.predictions[[1]] %>%
              mutate(model = "with sentiments")) %>%
  bind_rows(model_mean_BPM$.predictions[[1]] %>%
              mutate(model = "mean BPM")) %>%
  bind_rows(model_only_sentiment$.predictions[[1]] %>%
              mutate(model = "sentiments only"))

predictions %>%
  ggplot(aes(BPM, .pred, color = model)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.3) +
  facet_wrap(~ model) + 
  theme(legend.position="none") +
  labs(
      title = "Predicted BPM values vs. true BPM values",
      subtitle = "Calculated for each model", 
      y = "predicted BPM"
    ) + 
  theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    ) 
```

```{r metrics, message = FALSE, eval = TRUE, echo = FALSE}
metrics <- model$.metrics[[1]] %>%
  mutate(model = "without sentiments") %>%
  bind_rows(model_with_sentiment$.metrics[[1]] %>%
              mutate(model = "with sentiments")) %>%
  bind_rows(model_mean_BPM$.metrics[[1]] %>%
              mutate(model = "mean BPM")) %>%
  bind_rows(model_only_sentiment$.metrics[[1]] %>%
              mutate(model = "sentiments only"))

metrics %>%
  select(.metric, .estimate, model)

metrics %>%
  select(.metric, .estimate, model) %>%
  ggplot(aes(x = .estimate, y = fct_reorder(model,.estimate))) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  facet_wrap(~ .metric, scales = "free") +
  geom_text(aes(label=round(.estimate,4)), position=position_dodge(width=0.9), vjust=-0.25) + 
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1)) + 
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +
  labs(
      title = "RMSE (Root Mean Square Error) and RSQ (R-Squared) ",
      subtitle = "Calculated for each model"
    ) + 
  theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Therefore, to determine which model predicted the values best, the RMSE and RSQ (R-Squared: proportion of variance in the dependent variable that can be explained by the independent variables) was used to further analyze the different models.
The bar plot shows that the RMSE are in the range of 7.7049 to 8.1546. Using RMSE as a metric the model without sentiment scores predicts the BPM best. The difference between the RSQ of the models on the other hand is quite large. Here, all models don't explain the BPM well ranging from 0.0187 to 0.1007. 
So even here, a direct influence of the sentiments as a feature can not be derived from the model, underlining our findings in the correlation analysis that the sentiments have no significant influence on a players' in-game performance.

```{r variable_importance, message = FALSE, eval = TRUE, echo = FALSE}
get_variable_importance <- function(x, name){
  list <- x %>%
  pluck(".workflow", 1) %>%
  pull_workflow_fit()
  
  variable <- list$fit$variable.importance %>% names()
  value <- list$fit$variable.importance %>% unlist() %>% unname()

  data.frame(variable, value) %>%
    mutate(sentiment = ifelse(variable %in% c("bing", "syuzhet", "jockers_rinker", "nrc", "afinn", "novak_emoji"),T,F)) %>%
    ggplot(aes(x = fct_reorder(variable,value), y = value, fill = sentiment)) +
    geom_bar(stat= "identity") +
    coord_flip() +
    theme(legend.position="none") +
    xlab("feature") +
    ylab("importance for prediction") +
    scale_fill_manual(values = c("#595959", "#DB2C2C"))+
  labs(
      title = "Variable Importance Scores",
      subtitle = paste("Model:",name, sep=" ")
    ) + 
  theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    ) 
} 

get_variable_importance(model, "without sentiments")
get_variable_importance(model_with_sentiment, "with sentiments")
get_variable_importance(model_only_sentiment, "sentiments only")
```

As last step we looked at the importance scores of each sentiment analyzer method for the model including sentiments. Here it can be observed that the syuzhet and jockers_rinker sentiment scores rank first and second. The (permutation) importance score is calculated by (1) measuring a basline RSQ , (2) permuting the values of one feature and measure the RSQ. The importance score is the difference between the basline and the drop in overall RSQ caused by the permutation.
The plot indicates a high influence of sentiment scores, but since the model has a low RSQ, this should be perceived carefully. To further understand the influence of sentiment scores, a new model should be deployed in further research with the goal to increase the RSQ and analyze the feature importance again.

## 9. Conclusion and Further Considerations
### 9.1 Wrapping It Up
To the end of our project it is time to dedicate a section to the final results and findings of the whole work. It turned out that the most consuming tasks were not only to run the exploratory analyses on our data but also to gather and preprocess the data itself. Especially the processing of the twitter data has held some unexpected challenges, namely the proper handling of emojis, which we solved with an own sentiment lexicon, and the overall handling of the Twitter API, which turned out to be more complex than expected. Nonetheless we were able to generate meaningful data, that contains all variables needed to run some interesting analyses on it. Especially Twitter offered a wide range of metadata that got delivered with each tweet (e.g. the retweet count, which was vital for one of our correlation approaches).\newline

With the exploratory data analysis we wanted to answer our initial research questions. For this purpose we ran different approaches over the data to check, whether there is a significant correlation between the average sentiment of tweets a player receives before a game and his performance in-game. Unfortunately, it is to say, that our hypothesis doesn't hold and there is no such significance to be observed. \newline

To further investigate the findings we made, we wanted to elaborate the impact of the sentiments on a prediction model that predicts the players BPM performance score. The idea: If the sentiments highly contribute to the prediction and this prediction then is relatively good, it could be interpreted as indicator, that the significant correlation exists after all and we just made some mistakes in the analysis setup. And indeed did the majority of the sentiment scores highly contribute to the prediction. But unfortunately the prediction was quite poor. This could be interpreted as the sentiments pushing the predictor into a wrong learning direction and therefore are not significantly correlated to the prediction outcome.

### 9.2. Further Considerations
Reflecting the overall project and its outcome some consideration regarding the whole project setup can be done:\newline
1. For the twitter data, domain specific and more advanced sentiment extraction methods could be found or existing analyzers be tuned
2. For the prediction model, the input variables should be reviewed to gain a better prediction outcome
3. Generally the correlation analysis could be decoupled from the BPM performance variable and be applied to component variables of the BMP score (e.g. a correlation between the sentiments and the 3-point-field-goal percentage)
4. Further assumptions could be incorporated into the process, like the fact that some players don't manage their own twitter accounts at all but let professional social-media agencies monitor the activities. Such accounts are of course irrelevant for our analysis

## 10. References