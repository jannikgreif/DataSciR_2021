---
title: "Exploratory Data Analysis (EDA)"
author: "Frank Dreyer"
date: "19 6 2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(tidytext)
library(ggwordcloud)
library(stringr)
library(ggpubr)

knitr::opts_chunk$set(
  echo = FALSE, 
  eval = FALSE, 
  message = FALSE,
  warning = FALSE, 
  fig.show = "asis"
)

data_dir <- "../data"
tweets_dir <- data_dir %>% paste("tweets", sep = "/")
sentiments_dir <- data_dir %>% paste("sentiments", sep = "/")
```


```{r load_nba_stats, eval = TRUE}
player_metadata <- paste(data_dir,"player-metadata.csv", sep ="/") %>% read_csv()
player_game_stats <- paste(data_dir,"player-game-stats.csv", sep ="/") %>% read_csv()
game_metadata <- paste(data_dir,"game-metadata.csv", sep ="/") %>% read_csv()
player_season_stats <- paste(data_dir,"player-season-stats.csv", sep ="/") %>% read_csv()
```


```{r load_tweets, eval = TRUE}
tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

prep_tweets <- data_dir %>% 
  paste("prep-tweets.csv", sep = "/") %>% 
  read_csv()
```


```{r load_sentiments, eval = TRUE}
sentiment_names <- c("bing", "syuzhet", "jockers_rinker", "afinn", "nrc", "novak_emoji")

sentiments <- sentiment_names %>% 
  map_dfr(~ {
    sentiment_name <- .x
    
    sentiment_file <- sentiments_dir %>% 
      paste(sentiment_name, sep = "/") %>% 
      paste0(".csv") %>% 
      str_replace("_", "-")
    
    sentiments_tmp <- read_csv(sentiment_file) %>% 
      mutate(positive_sentiment = if_else(ave_sentiment >= 0, TRUE, FALSE)) %>% 
      mutate(sentiment_lexicon = sentiment_name)
      
  })
```

## Comparability of the Sentiment Lexicons

In the beginning we wanted to assess if the sentiment scores the different sentiment lexicons provided for tweets were actually comparable. For that purpose we computed the Spearman rank correlation coefficient between tweet sentiment scores provided by each pair of sentiment lexicons to assess whether the ranking of the tweets according to one sentiment lexicon agrees with the ranking of the tweets according to another sentiment lexicon. 

```{r compute_sentiment_consensus_spearman, eval = TRUE}
sentiment_lexicons <- sentiments$sentiment_lexicon %>% unique()

# Create cross product of sentiment_lexicon with itself
sentiment_lexicons_a <- sentiment_lexicons %>% 
  rep(each = length(sentiment_lexicons))
sentiment_lexicons_b <- sentiment_lexicons %>% 
  rep(times = length(sentiment_lexicons))

# For each pair of sentiment lexicons compute Kendall rank correlation coefficient
sentiment_lexicon_consensus <- map2_dfr(sentiment_lexicons_a, sentiment_lexicons_b, ~ {
  
  sentiments_a <- sentiments %>% 
    filter(sentiment_lexicon == .x) %>% 
    mutate(ave_sentiment_a = ave_sentiment) %>% 
    select(id, ave_sentiment_a) 
  
  sentiments_b <- sentiments %>% 
    filter(sentiment_lexicon == .y) %>%
    mutate(ave_sentiment_b = ave_sentiment) %>% 
    select(id, ave_sentiment_b)
  
  inner_join(sentiments_a, sentiments_b) %>% 
    mutate(sentiment_lexicon_a = .x) %>% 
    mutate(sentiment_lexicon_b = .y) %>%  
    group_by(sentiment_lexicon_a, sentiment_lexicon_b) %>% 
    summarise(consensus = cor(ave_sentiment_a, ave_sentiment_b, method = "spearman", use = "complete.obs")) %>% 
    ungroup()
  
})
```

We then plotted the results into a heatmap:

```{r plot_sentiment_consensus, eval = TRUE, fig.width = 10}
sentiment_lexicon_consensus %>% 
  ggplot(mapping = aes(x = sentiment_lexicon_a, y = sentiment_lexicon_b)) +
    geom_tile(mapping = aes(fill = consensus)) +
    geom_text(mapping = aes(label = round(consensus, 3))) +
    scale_fill_gradient(low = "white", high = "red") + 
    labs(
      title = "Consensus of the Sentiment Lexicons in giving Sentiment\nScores to Tweets addressed to NBA Basketball Players", 
      subtitle = "Using the Spearman Rank Correlation Coefficient"
    ) +
    theme_minimal() + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.x = element_blank(),
      axis.title.y = element_blank()
    ) 
```

Generally we can see that except of the Emoji Sentiment Lexicon by Novak all other sentiment lexicons seem to correlate rather well. Apparently the computed tweet sentiments from the Emoji Lexicon differ strongly from the sentiments of the other lexicons which is reasonable since the Emoji Lexicon is only computed on the emojis contained in the tweet while the other lexicons use the textual information of the tweet. The Jockers Rinker and Syuzhet lexicons are most similar with a Spearman correlation coefficient around 0.95. This intuitively also makes sense since Jockers-Rinker is a combined version of Syuzhet and Bing as mentioned before.

## Computing Sentiment Aggregates

Since the sentiment scores were computed on a per-tweet basis we first had to aggregate the sentiment scores accordingly in order to capture the overall social media vibe players were receiving before games in a single number. For that purpose we considered  the sentiment scores of all tweets a respective player received in a 24-hour window before a respective game and aggregated them as follows:  

* The average of the sentiment scores (mean). 
* The average of the sentiment scores weighted by the retweet count of the associated tweet (weighted mean). 
* The proportion of tweets with a negative associated sentiment score (< 0).


```{r compute_sentiment_aggregates_24h_before_games, eval = TRUE}
tweets_24h_before_games <- player_game_stats %>%
  inner_join(game_metadata) %>% 
  inner_join(tweets) %>% 
  mutate(h_timediff_game = as.double(DateTime - created_at, units = "hours")) %>% 
  select(c(names(tweets), h_timediff_game))  %>%
  filter(h_timediff_game <= 24)

sentiment_aggregates_24h_before_games <- tweets_24h_before_games %>% 
  inner_join(sentiments) %>% 
  group_by(BBRef_Player_ID, BBRef_Game_ID, sentiment_lexicon) %>% 
  summarise(
    avg_sentiment = mean(ave_sentiment),
    avg_sentiment_retweet_cnt_weighted = weighted.mean(ave_sentiment, retweet_count),
    rel_freq_negative = sum(!positive_sentiment) / n()
  ) 
```

The following table shows an excerpt of the per-game computed sentiment aggregates for the different sentiment lexicons: 

```{r display_sentiment_aggregates_24h_before_games, eval = TRUE, message = TRUE}
sentiment_aggregates_24h_before_games
```

## Univariate Distribution Analysis

At this point we had all the necessary data to analyze the association between the aggregated sentiment scores of tweets the players received within 24 hours before games and their performance within the games. 

Before analyzing these bivariate relationships however we first wanted to get a general idea how the individual variables were distributed. 

### Distribution of the Sentiment Aggregates

Plotting the density curves for the unweighted average sentiment scores for the different sentiment lexicons and players revealed the following picture: 

```{r plot_density_curves_avg_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment)) +
    geom_density() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Density Plots of the Average Sentiments of Tweets Players were receiving within 24 Hours before Games", 
      subtitle = "For different Players and Sentiment Lexicons between the seasons 2017-18 and 2018-19", 
      x = "Average Tweet Sentiment", 
      y = "Density"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Looking at the individual density curves we observed that the distributions of the average sentiment scores rougly fit the bell curve of a Normal distribution despite a few exceptions (esp. for the averaged sentiments for the emoji sentiment lexicon by Novak). 

To check our normality assumption we also constructed Q-Q plots for the unweighted average sentiment scores: 

```{r plot_qq_plot_avg_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(sample = avg_sentiment)) + 
    geom_qq(alpha = 0.2) + 
    geom_qq_line() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Average Sentiments of Tweets Players were receiving within 24 Hours before Games", 
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

The Q-Q plots confirmed our assumption of normality, since despite some curve offs at the extremities (some observed extremes were more extreme than expected), most of the observed quantiles matched the expected quantiles of the fitted Normal distribution. 

A similar picture could be observed for the average weighted sentiment scores (weighted by their associated retweet count) as the following equivalent grid of Q-Q plots shows:

```{r plot_qq_plot_avg_weighted_sentiments, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(sample = avg_sentiment_retweet_cnt_weighted)) + 
    geom_qq(alpha = 0.2) + 
    geom_qq_line() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Average Sentiments of Tweets Players were\nreceiving within 24 Hours before Games weighted by their Retweet Count", 
      subtitle = "For different Players and Sentiment Lexicons between the Seasons  2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    ) 
```

The distributions for the negative tweet proportions mostly did not follow a Normal distribution and were strongly right skewed however. That intuitively made sense since in most of the cases players only received a small proportion of tweets with a negative sentiment which leads to the right skewness of the distribution (also because proportions cannot go below 0). The following grid of density plots emphasize that circumstance:

```{r plot_density_curves_weighted_rel_freq_negative, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = rel_freq_negative)) +
    geom_density() + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free")+ 
    labs(
      title = "Density Plots of the Proportion of Tweets with a negative Sentiment Players were receiving within 24 Hours before Games",
      subtitle = "For different Players and Sentiments Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Proportion of Negative Tweets", 
      y = "Density"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

### Distribution of the Box Plus/Minus Performance Indicator

Besides the sentiment aggregates we also studied how the BPM perfomance indicator values are distributed for the different players. Similar to the unweighted and weighted sentiment averages before, BPM was also normally distributed as the following grid of Q-Q plots indicates: 

```{r plot_qq_plot_BPM, eval = TRUE, fig.width = 10, fig.height = 30}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  mutate(variable = "BPM") %>% 
  distinct(Player, BBRef_Game_ID, BPM, variable) %>% 
  ggplot(mapping = aes(sample = BPM)) + 
    geom_qq(alpha = 0.4) + 
    geom_qq_line() + 
    facet_grid(Player ~ variable, scales = "free") + 
    labs(
      title = "Normal Q-Q Plots of the Box Plus/Minus (BPM) Performance Indicator",
      subtitle = "For different Players between the Seasons 2017-18 and 2018-19", 
      x = "Normal Theoretical Quantiles", 
      y = "Observed Quantiles"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Knowing that the BPM values were normally distributed for the different players it was sufficient to simply construct boxplots for the performance indicator to get a sense how the individual players performed in general and how their performance fluctuated over the two considered seasons. 

```{r plot-boxplot-BPM, eval = TRUE, fig.width = 10}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  distinct(Player, BBRef_Game_ID, BPM) %>% 
  ggplot(mapping = aes(x = reorder(Player, BPM, na.rm = TRUE), y = BPM)) + 
    geom_boxplot() + 
    coord_flip() +
    labs(
      title = "Boxplots of the Box Plus/Minus (BPM) Performance Indicator",
      subtitle = "For different Players between the Seasons 2017-18 and 2018-19", 
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.y = element_blank()
    ) 
```

## Bivariate Distribution and Correlation Analysis

After having observed the univariate distributions of the variables that were of importance for this analysis we now wanted to assess whether there is a relationship between the individual sentiment aggregates and the BPM values for any of the individual players and sentiment lexicons. 

### Relationship between the Average 24-Hour Tweet Sentiment and the BPM Performance Indicator

We began by having a closer look at the relationship between the unweighted sentiment average and the BPM performance indicator. For that purpose we created a grid of scatterplots for each player and sentiment lexicon combination and fitted a simple linear regression line through each of the resulting point clouds. Additionally, to measure the strength and direction of a potential bivariate linear relationships, we made use of the `ggpubr`-library by adding the corresponding Pearson correlation coefficient *r* and its associated *p*-value (using a T-test statistic with n-2 degrees of freedom) to each scatterplot. It should be noted here that the Pearson correlation coefficient was applicable since both variables were normally distributed as indicated before. Furthermore, we added the *p*-value to measure how significant the corresponding Pearson correlation coefficient deviated from zero (no correlation / linear relationship). The resulting plot is represented below.

```{r plot_relationship_avg_sentiments_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "pearson", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Average Sentiment of Tweets Players received\nwithin 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Average Tweet Sentiment",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

As one can see, the points of the different scatterplots appeared rather scattered and for the different sentiment lexicons and players there was neither a strong nor direclty visible (linear) relationship between the average tweet sentiment and the BPM performance indicator. Even though some of the linear regression lines suggested a correlation, the correlations themselves were rather weak or even neglectable as indicated by the respective Pearson correlation coefficients *r* that were relatively small (mostly less than 0.1). Additionally most of the *p*-values of the associated Pearson correlation coefficients were rather high which suggested that the observed strength of the correlations were not significantly different from 0 (and might have appeared due to random chance). 

Nevertheless, there were also some counter examples where the Pearson correlation coefficient appeared rather significant. The player Jaylen Brown for example showed a positive correlation for the Afinn lexicon with a *p*-value below 0.05. However, since the correlations were rather weak, not significant and somehow contradicting for other sentiment lexicons (compare that the correlation was negative for the nrc lexicon), it is debatable if the positive correlation is generalizable for the entire population or even the single player alone. 

Due to these reasons we had to conclude that there is no evidence of a significantly strong linear correlation between the average sentiment of tweets players receive within 24 hours before games and their performance within the games. 

There was however another interesting observation the scatterplots revealed, namely the prominent outliers. For almost every player there was at least one game day in which the average tweet sentiment was vastly more positive compared to other days. Additionally there were some players with game days associated with an extremely negative average tweet sentiment in comparison to other days. To investigate these outliers more closely we created two word clouds for each player, one for the worst average tweet sentiment the player received and one for the best. We used the tweet sentiments created from the Jockers-Rinker lexicon for this purpose and mapped the 50 most frequent words that appeared in the corresponding tweets on each wordcloud. 

```{r compute_rel_word_frequencies_extreme_sentiments, eval = TRUE}
worst_sentiments <- sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, - avg_sentiment) %>% 
  mutate(extreme_type = "Worst Sentiment")

best_sentiments <- sentiment_aggregates_24h_before_games %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  group_by(BBRef_Player_ID) %>% 
  top_n(1, avg_sentiment) %>% 
  mutate(extreme_type = "Best Sentiment")

word_frequencies <- bind_rows(worst_sentiments, best_sentiments) %>% 
  inner_join(player_metadata) %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  mutate(prep_text = str_remove_all(prep_text, "[:digit:]")) %>% 
  drop_na(prep_text) %>% 
  group_by(Player, extreme_type) %>% 
  unnest_tokens(word, prep_text) %>% 
  anti_join(stop_words) %>%
  group_by(Player, extreme_type, word) %>% 
  summarise(freq = n()) 

rel_word_frequencies <- word_frequencies %>% 
  group_by(Player, extreme_type) %>% 
  summarise(total = sum(freq)) %>% 
  inner_join(word_frequencies) %>% 
  mutate(rel_freq = freq / total)
```


```{r plot_word_clouds_extreme_sentiments, eval = TRUE, fig.width = 10, fig.height = 35}
rel_word_frequencies %>% 
  
  # Min/Max-Scaling for visibility 
  group_by(Player, extreme_type) %>% 
  summarise(max_rel_freq = max(rel_freq), min_rel_freq = min(rel_freq) ) %>% 
  inner_join(rel_word_frequencies) %>% 
  mutate(rel_freq_scaled = (rel_freq - min_rel_freq) / (max_rel_freq - min_rel_freq) + 1) %>% 
  
  # Used for diverging color scale
  mutate(
    rel_freq_color = if_else(
      extreme_type == "Worst Sentiment", 
      (-1) * rel_freq_scaled,
      rel_freq_scaled
    )
  ) %>% 
  
  # To display higher frequency terms in the middle
  arrange(desc(rel_freq)) %>% 
  
  # Select top 50 of the highest frequent terms for the worst and best avg. sentiment of each player
  group_by(Player, extreme_type) %>%
  slice_head(n = 50) %>% 
  
  # Plot result
  ggplot(mapping = aes(label = word, size = rel_freq_scaled, color = rel_freq_color)) + 
    geom_text_wordcloud_area(rm_outside = TRUE) + 
    scale_size_area(max_size = 8) + 
    scale_color_gradient2(low = "blue", high = "red") +
    facet_grid(Player ~ extreme_type) +
    theme_minimal()
```

The most prominent observation derived from the wordclouds was that the best average sentiments were frequently associated with the words "happy" and "birthday", which indicated that these players were receiving birthday wishes on that same game day. Besides birthdays it appeared that other players received positive tweet sentiments due to another important day or event in their life. For stephen curry the terms "baby", "congrats", "boy", "family", "hands", "blue" and "eyes" occurred rather frequently. By having a glimpse on the tweets he received that day we can see people were congratulating him for another baby that was on the way: 

```{r compute_best_sentiment_tweets_stephen_curry, eval = TRUE, message = TRUE}
best_sentiments %>% 
  inner_join(player_metadata) %>% 
  filter(Player == "Stephen Curry") %>%
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  select(prep_text)
```

For the worst sentiments the picture was not that clear on the other hand. Jamal Murray for example also frequently received the words "happy" and "birthday" on the game day with the worst average tweet sentiment. By a closer look on the tweets themselves however, we saw that he was only tagged on 22 tweets that day and that the birthday wishes were actually addressed to the player Dejuan Wagner, but not himself:

```{r display_worst_sentiment_tweets_jamal_murray, eval = TRUE, message = TRUE}
worst_sentiments %>% 
  inner_join(player_metadata) %>% 
  filter(Player == "Jamal Murray") %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  select(prep_text)
```

One noticeable observation was that swear words tended to appear more frequently in the associated tweets. E.g with regard to the worst sentiment game of Klay Thompson the terms "shots", "missed" and "bad", in combination with several swear words reflect a situation where the player received some hate due to some missed shots from a previous game. The example tweets are displayed below:

```{r display_worst_sentiment_tweets_klay_thompson, eval = TRUE}
worst_sentiments %>% 
  inner_join(player_metadata) %>% 
  filter(Player == "Klay Thompson") %>% 
  inner_join(tweets) %>% 
  inner_join(prep_tweets) %>% 
  filter(str_detect(prep_text, "bad|fucking|mad|fuck|fucking|missed")) %>% 
  select(prep_text)
```

Nevertheless it was hard to make a general conclusion why the players received such bad tweet sentiments on the associated days from the most frequent terms alone. 

### Relationship between the Weighted Average 24-Hour Tweet Sentiment and the BPM Performance Indicator

One might argue that players who receive over a thousand tweets each day, is not capable of reading or even noticing all the tweets he receives. Due to this we made the assumption, that those tweets, which have a higher retweet count also have a higher likelihood of being read. Considering this, we now used the retweet-count-weighted sentiments, which already got created before, for the computation of the the mean sentiment and created a correlation plot like we did in the previous section.

```{r plot_relationship_weighted_avg_sentiments_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = avg_sentiment_retweet_cnt_weighted, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "pearson", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Retweet Count Weighted Average Sentiment of Tweets Players\nreceived within 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Retweet Count Weighted Average Tweet Sentiment",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Generally we can say that the weighted average sentiment also did not reveal any better correlation results. There were however also some exceptions. For Josh Richardson the Pearson correlation coefficients appeared to be rather significant with *p*-values less than 0.1 for the different sentiment lexicons (except for the emoji lexicon by Novak). Despite the fact that these correlations were all positive for this player, they were still quite weak however, with a maximum Pearson correlation coefficient of 0.29 for the Jockers-Rinker sentiment lexicon. Additionally it is to say that this is an exception and does not alter the general observation much.

### Relationship between the Proportion of Negative Tweets and the BPM Performance Indicator

We created the same plot a third time, but now only considering the proportion of negative tweets a player received at each respective game. Since the distributions of the negative proportions were heavily right skewed and not normally distributed, we used the Kendall-Tau rank correlation coefficient instead of the Pearson metric. 

```{r plot_relationship_rel_freq_negative_tweets_BPM, eval = TRUE, fig.width = 10, fig.height = 35}
player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  ggplot(mapping = aes(x = rel_freq_negative, y = BPM)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(method = "lm", se = FALSE, color = "red") + 
    stat_cor(method = "kendall", cor.coef.name = "r", size = 3, label.padding = 0) + 
    scale_y_continuous(limits = c(-20, 35)) + 
    facet_grid(Player ~ sentiment_lexicon, scales = "free_x") + 
    labs(
      title = "Relationship between the Proportion of Tweets with a Negative Sentiment Players\nreceived within 24 Hours before Games and their BPM Value within the Games",
      subtitle = "For different Players and Sentiment Lexicons between the Seasons 2017-18 and 2018-19", 
      x = "Relative Frequency of Negative Tweets",
      y = "Box Plus/Minus (BPM)"
    ) + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Unfortunately, this aggregate delivered a similar picture regarding the correlation we wanted to inspect.

### Time Dependent Relationship between the Average Tweet Sentiments and the BPM Performance Indicator

Finally, we investigated if there is maybe a time dependent relationship between the average sentiment score and the BPM value the players received. For that purpose we exemplary plotted the Jockers-Rinker average sentiments and the BPM values against the game dates on which they were observed for each player for the season 2018-19. Since both variables fluctuated quite strongly over the considered timespan we overlaid a smoothed average line to improve the interpretation ability. The resulting plot is displayed below. 

```{r season_18_19_trend_BPM_vs_jockers_rinker, eval = TRUE, message = TRUE, fig.width = 10, fig.height = 80}
scaling_coef <- 60

player_metadata %>% 
  inner_join(player_game_stats) %>% 
  inner_join(sentiment_aggregates_24h_before_games) %>% 
  filter(SeasonType == "Regular Season") %>% 
  filter(Season %in% c("2018-19")) %>% 
  filter(sentiment_lexicon == "jockers_rinker") %>% 
  rename(jockers_rinker = avg_sentiment) %>% 
  ggplot(mapping = aes(x = Date)) +
  
    geom_smooth(mapping = aes(y = BPM), se = FALSE, color = "blue") + 
    geom_line(mapping = aes(y = BPM), color = "blue", alpha = 0.2) + 
  
    geom_smooth(mapping = aes(y = jockers_rinker * scaling_coef), se = FALSE, color = "red") +
    geom_line(mapping = aes(y = jockers_rinker * scaling_coef), color = "red", alpha = 0.2) + 
  
    facet_wrap(~ Player, ncol = 1) +
  
    scale_y_continuous( 
      name = "Box Plus/Minus (BPM)",
      sec.axis = sec_axis(~./scaling_coef, name = "Jockers-Rinker Sentiment Average")
    ) + 
    coord_cartesian(ylim = c(-10,20)) + 
    labs(
      title = "Time-Dependent Relationship between the Average Sentiments of Tweets Players received\nwithin 24 Hours before Games and their BPM Value within the Games in the season 2018-19", 
      subtitle = "Using the Jockers-Rinker Sentiment Average"
    ) +
    theme_minimal() + 
    theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5),
      axis.title.y = element_text(color = "blue"),
      axis.title.y.right = element_text(color = "red")
    )
```

As one can see, there appeared to be also no time-dependent association between the variables.

Concluding to this section we can wrap up our observations as follows:

 * The desired positive correlation between the average sentiments of tweets related to one specific player and game could not be found with any of the approaches described.
 * Therefore, based on our analyses, it is to assume that our main hypothesis does not hold true and there is no significant correlation between these two variables.
