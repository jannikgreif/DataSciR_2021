---
title: "Predictive Model"
weight: 5
chapter: yes
---

<style>#chapter p {
text-align: justify} #chapter h3 {
text-align: left}
</style>

## 5. Predictive Model

### 5.1 Model Design

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(tidyverse)
library(purrr)
library(rvest)
library(tidymodels)
```

One attempt to check whether the sentiments have an influence on the players performance at all and therefore to investigate our findings in the correlation analysis was to set up a random forest regression model to predict the BPM of players. We used different models and compared the BPM predictions. The following models were used:

 - mean BPM of the last 5 BPMs as a baseline model
 - model including only the sentiment scores
 - model including the last 5 BPMs, Position, Age, Month of the Game, Homegame, Trend, SRS_Team, SRS_Opponent
 - model including the last 5 BPMs, Position, Age, Month of the Game, Homegame, Trend, SRS_Team, SRS_Opponent and the sentiment scores
 
In detail, Homegame expresses whether the player played a homegame (1) or an away game (0). The Trend indicates the teams last 5 game performances - i.e. the sum of wins (+1) and losses (-1) is calculated. In order to measure a more longterm team performance we used the SRS (Simple Rating System) which assigns a score to each team according to their average point difference and strength of schedule (0 marks the average score). The SRS for the previous season was used for the prediction.

```{r load_tweets_and_transform, message = FALSE, include = FALSE, warning=FALSE, cache=TRUE}
data_dir <- "../../../data"
sentiments_dir <- "../../../data/sentiments"
tweets_dir <- data_dir %>% paste("tweets", sep = "/")

tweets <- list.files(tweets_dir, full.names = TRUE) %>% 
  map_dfr(read_csv)

player_game_stats <- data_dir %>% paste("player-game-stats.csv", sep = "/") %>% read_csv()
player_season_stats <- data_dir %>% paste("player-season-stats.csv", sep = "/") %>% read_csv()

games <- tweets %>% 
  select(BBRef_Player_ID ,BBRef_Game_ID) %>%
  unique() %>%
  left_join(player_game_stats %>% select(BBRef_Player_ID,BBRef_Game_ID,Season, Date, Tm, HTm, Opp, WL,BPM), by = c("BBRef_Player_ID" = "BBRef_Player_ID", "BBRef_Game_ID" = "BBRef_Game_ID")) %>%
  left_join(player_season_stats %>% select(BBRef_Player_ID,Season, Age, Pos), by = c("BBRef_Player_ID" = "BBRef_Player_ID", "Season" = "Season")) %>%
  unique()

player_game_stats <- player_game_stats %>%
  mutate(index = 1:nrow(player_game_stats)) %>% # get an index in order to use for the last 5 BPMs
  mutate(WL_ = ifelse(str_detect(player_game_stats$WL, "W"),1,-1)) # use for trend variable

games <- games %>%
  mutate(Homegame = ifelse(games$Tm == games$HTm,1,0)) %>%
  mutate(Month = month(Date))

get_BPM_Trend <- function(player, game){
  index <- player_game_stats %>%
    filter(BBRef_Player_ID == player,BBRef_Game_ID == game) %>%
    select(index) %>%
    pull()
  
  games <- games %>%
    filter(BBRef_Player_ID == player,BBRef_Game_ID == game) %>%
    mutate(BPM_5 = player_game_stats$BPM[index-5]) %>%
    mutate(BPM_4 = player_game_stats$BPM[index-4]) %>%
    mutate(BPM_3 = player_game_stats$BPM[index-3]) %>%
    mutate(BPM_2 = player_game_stats$BPM[index-2]) %>%
    mutate(BPM_1 = player_game_stats$BPM[index-1]) %>%
    mutate(Trend = sum(player_game_stats$WL_[(index-5):(index-1)]))
}

games <- map2_dfr(games$BBRef_Player_ID, games$BBRef_Game_ID, ~ get_BPM_Trend(.x, .y)) # get the last 5 BPMs and Trend for each player/game combination
content <- read_html("https://www.basketball-reference.com/leagues/NBA_2018.html")
tables <- content %>% html_table(fill = TRUE)
team_stats_2018 <- tables[[11]]

team_stats_2018 <- team_stats_2018[,c(2,10)] %>% 
  tail(-1) %>% 
  head(-1) %>%
  setNames(c("Team","SRS")) %>%
  mutate(SRS = as.double(SRS)) %>%
  mutate(Team_name = c("HOU","TOR","GSW","UTA","PHI","BOS","OKC","SAS","POR","MIN","DEN","IND","NOP","CLE","WAS","MIA","CHO","LAC","DET","MIL","LAL","DAL","NYK","BRK","ORL","ATL","MEM","CHI","SAC","PHO")) %>%
  mutate(Season_plus_one = "2018-19")

content <- read_html("https://www.basketball-reference.com/leagues/NBA_2017.html")
tables <- content %>% html_table(fill = TRUE)
team_stats_2017 <- tables[[11]]

team_stats_2017 <- team_stats_2017[,c(2,10)] %>% 
  tail(-1) %>% 
  head(-1) %>%
  setNames(c("Team","SRS")) %>%
  mutate(SRS = as.double(SRS)) %>%
  mutate(Team_name = c("GSW","SAS","HOU","TOR","LAC","UTA","CLE","BOS","WAS","MIA","OKC","MEM","DEN","CHI","CHO","IND","MIL","POR","ATL","DET","MIN","NOP","DAL","NYK","SAC","PHO","PHI","BRK","ORL","LAL")) %>%
  mutate(Season_plus_one = "2017-18")

team_stats <- rbind(team_stats_2017,team_stats_2018)

games <- games %>% 
  left_join(team_stats, by = c("Season" = "Season_plus_one", "Tm" = "Team_name")) %>%
  left_join(team_stats, by = c("Season" = "Season_plus_one", "Opp" = "Team_name"))

data <- games %>%
  select(BBRef_Player_ID,BBRef_Game_ID,Age,Pos,BPM_5,BPM_4,BPM_3,BPM_2,BPM_1,Homegame, Month,SRS_Tm = SRS.x , SRS_Opp = SRS.y, BPM, Trend) %>%
  mutate(mean_BPM = rowMeans(games %>%select(BPM_5,BPM_4,BPM_3,BPM_2,BPM_1),na.rm = TRUE)) 

prep_tweets <- data_dir %>% paste("prep-tweets.csv", sep = "/") %>% read_csv()
bing <- sentiments_dir %>% 
  paste("bing.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, word_count, ave_sentiment)) %>% 
  rename(bing = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(bing < 0.0, "negative", "positive"))

syuzhet <- sentiments_dir %>% 
  paste("syuzhet.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(syuzhet = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(syuzhet < 0.0, "negative", "positive"))

jockers_rinker <- sentiments_dir %>% 
  paste("jockers-rinker.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(jockers_rinker = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(jockers_rinker < 0.0, "negative", "positive"))

afinn <- sentiments_dir %>% 
  paste("afinn.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(afinn = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(afinn < 0.0, "negative", "positive"))

nrc <- sentiments_dir %>% 
  paste("nrc.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(nrc = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(nrc < 0.0, "negative", "positive"))

novak_emoji <- sentiments_dir %>% 
  paste("novak-emoji.csv", sep = "/") %>% 
  read_csv() %>% 
  select(c(id, ave_sentiment)) %>% 
  rename(novak_emoji = ave_sentiment) %>%
  mutate(binary_sentiment = if_else(novak_emoji < 0.0, "negative", "positive"))

sentiments <- tweets %>% 
  inner_join(prep_tweets) %>% 
  select(c(BBRef_Player_ID,BBRef_Game_ID,id, text, prep_text)) %>% 
  inner_join(bing) %>%
  inner_join(syuzhet) %>% 
  inner_join(jockers_rinker) %>% 
  inner_join(nrc) %>% 
  inner_join(afinn) %>% 
  inner_join(novak_emoji)

aggregated_sentiments <- sentiments %>% 
  group_by(BBRef_Player_ID, BBRef_Game_ID) %>% 
  summarize(bing = mean(bing), syuzhet = mean(syuzhet), jockers_rinker = mean(jockers_rinker), 
            nrc = mean(nrc), afinn = mean(afinn), novak_emoji = mean(novak_emoji))

data <- data %>% 
  left_join(aggregated_sentiments, by = c("BBRef_Player_ID" = "BBRef_Player_ID", "BBRef_Game_ID" = "BBRef_Game_ID"))


data <- data %>% drop_na(BPM,BPM_5,BPM_4,BPM_3,BPM_2,BPM_1,bing,syuzhet,jockers_rinker,nrc,afinn)
```

### 5.2 Predictions

For the actual prediction task we started by selecting 
the relevant columns for the model and split the data 
into training and testing data with a proportion of 75%
training and 25% testing. A validation split was performed in order to 
combat overfitting. Each model was created using 
the recipe package. Using tune_grid(), the model 
parameter mtry (number of predictors that will be 
randomly sampled at each split when creating the tree 
models), trees (number of trees contained in the 
ensemble) and min_n (minimum number of data points in a
node that are required for the node to be split 
further) got tuned. After tuning, we chose the best model fit 
based on the RMSE (Root Mean Square Error) 
which calculates the average distance between the 
predicted values and the true values, i.e. the lower 
the RMSE, the better the model is able to fit a 
dataset. The importance score for each variable was 
saved as well.

```{r predictive_model, message = FALSE, include = FALSE, cache=TRUE}
data <- data %>%
  select(Pos, Age, BPM_5, BPM_4, BPM_3, BPM_2, BPM_1, Homegame, Month, SRS_Tm, SRS_Opp, Trend, bing, syuzhet, jockers_rinker, nrc, afinn, novak_emoji, BPM, mean_BPM) %>% 
  drop_na(BPM,BPM_5,BPM_4,BPM_3,BPM_2,BPM_1,bing,syuzhet,jockers_rinker,nrc,afinn)

set.seed(123)
data_split <- initial_split(data)
data_train <- training(data_split)
data_test <- testing(data_split)
val_set <- validation_split(data_train, prop = 0.8)

# normal model
rf_rec <- recipe(BPM ~ BPM_5 + BPM_4 + BPM_3 + BPM_2 + BPM_1 + Pos + Age + Month + Homegame + Trend + SRS_Tm +  SRS_Opp, data = data_train) 

# model with sentiments
rf_rec_with_sentiment <- recipe(BPM ~ BPM_5 + BPM_4 + BPM_3 + BPM_2 + BPM_1 + Pos + Age + Month + Homegame + Trend + SRS_Tm +  SRS_Opp + bing + syuzhet + jockers_rinker + nrc + afinn + novak_emoji, data = data_train) 

# model with mean BPM
rf_rec_mean <- recipe(BPM ~ mean_BPM, data = data_train)

# model sentiments only
rf_rec_only_sentiment <- recipe(BPM ~ bing + syuzhet + jockers_rinker + nrc + afinn + novak_emoji, data = data_train)

get_model <- function(rec){
  rf_spec <- rand_forest(
  mtry = tune(),
  min_n = tune(),
  trees = tune()) %>%
  set_engine("ranger") %>%
  set_mode("regression")
  
  rf_wf <- workflow() %>%
  add_model(rf_spec) %>%
  add_recipe(rec)  

  rf_res <- rf_wf %>%
  tune_grid(val_set,
            grid = 100,
            control = control_grid(save_pred = TRUE))  
  
  rf_best <- rf_res %>%
  select_best(metric = "rmse")
  
  last_rf_spec <- rand_forest(mtry = rf_best$mtry[1], min_n = rf_best$min_n[1], trees = rf_best$trees[1]) %>%
  set_engine("ranger", importance ="permutation") %>%
  set_mode("regression")

last_rf_wf <- rf_wf %>%
  update_model(last_rf_spec)

last_rf_fit <- last_rf_wf %>%
  last_fit(data_split)
}

model <- get_model(rf_rec)
model_with_sentiment <- get_model(rf_rec_with_sentiment)
model_mean_BPM <- get_model(rf_rec_mean)
model_only_sentiment <- get_model(rf_rec_only_sentiment)
```

In order to determine which model predicted the BPM 
performance best, a visualization is shown below that 
displays the predicted values (y-axis) and the true values 
(x-axis) for each model, meaning a perfectly fitted model 
would align all points on the the 45Â° line. The 
visualization doesn't allow for a clear interpretation since 
all models are scattered and no specific trend can be 
observed.

```{r predictions, message = FALSE,include = FALSE}
predictions <- model$.predictions[[1]] %>%
  mutate(model = "without sentiments") %>%
  bind_rows(model_with_sentiment$.predictions[[1]] %>%
              mutate(model = "with sentiments")) %>%
  bind_rows(model_mean_BPM$.predictions[[1]] %>%
              mutate(model = "mean BPM")) %>%
  bind_rows(model_only_sentiment$.predictions[[1]] %>%
              mutate(model = "sentiments only"))
```
 
```{r modelvisualisation_predictions, eval = TRUE, fig.width = 10, echo = FALSE}
predictions %>%
  ggplot(aes(BPM, .pred, color = model)) +
  geom_abline(lty = 2, color = "gray80", size = 1.5) +
  geom_point(alpha = 0.3) +
  facet_wrap(~ model) + 
  theme(legend.position="none") +
  labs(
      title = "Predicted BPM values vs. true BPM values",
      subtitle = "Calculated for each model", 
      y = "predicted BPM"
    ) + 
  theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    ) 
```

```{r metrics, message = FALSE, include = FALSE}
metrics <- model$.metrics[[1]] %>%
  mutate(model = "without sentiments") %>%
  bind_rows(model_with_sentiment$.metrics[[1]] %>%
              mutate(model = "with sentiments")) %>%
  bind_rows(model_mean_BPM$.metrics[[1]] %>%
              mutate(model = "mean BPM")) %>%
  bind_rows(model_only_sentiment$.metrics[[1]] %>%
              mutate(model = "sentiments only"))
```

### 5.3 RMSE and RSQ

```{r modelvisualisation_metrics, eval = TRUE, fig.width = 10, echo = FALSE}
metrics %>%
  select(.metric, .estimate, model) %>%
  ggplot(aes(x = .estimate, y = fct_reorder(model,.estimate))) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  facet_wrap(~ .metric, scales = "free") +
  geom_text(aes(label=round(.estimate,4)), position=position_dodge(width=0.9), vjust=-0.25) + 
  theme(legend.position="none") +
  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1)) + 
  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) +
  labs(
      title = "RMSE (Root Mean Square Error) and RSQ (R-Squared) ",
      subtitle = "Calculated for each model"
    ) + 
  theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
```

Therefore, to determine which model predicted the values 
best, the RMSE (Root Mean Square Error: calculates the average distance between the 
predicted values and the actual values) and RSQ (R-Squared: proportion of variance in 
the dependent variable that can be explained by the 
independent variables) was used to further analyze the 
different models.
The bar plot shows that the RMSE are in the range of `r metrics %>% filter(.metric == "rmse") %>% select(.estimate) %>% min() %>% round(2)` - `r metrics %>% filter(.metric == "rmse") %>% select(.estimate) %>% max() %>% round(2)`. Using RMSE as a metric the model without sentiment scores predicts 
the BPM best. The difference between the models RSQ on the 
other hand is quite large. Here, all models don't explain the
BPM well ranging from `r metrics %>% filter(.metric == "rsq") %>% select(.estimate) %>% min()` to `r metrics %>% filter(.metric == "rsq") %>% select(.estimate) %>% max()`. 
So even here, a direct influence of the sentiments as a 
feature can not be derived from the model, underlining our 
findings in the correlation analysis that the sentiments have no significant influence on a players in-game performance.

### 5.4 Variable Importance Scores

```{r variable_importance, message = FALSE, include = FALSE}
get_variable_importance <- function(x, name){
  list <- x %>%
  pluck(".workflow", 1) %>%
  pull_workflow_fit()
  
  variable <- list$fit$variable.importance %>% names()
  value <- list$fit$variable.importance %>% unlist() %>% unname()

  data.frame(variable, value) %>%
    mutate(sentiment = ifelse(variable %in% c("bing", "syuzhet", "jockers_rinker", "nrc", "afinn", "novak_emoji"),T,F)) %>%
    ggplot(aes(x = fct_reorder(variable,value), y = value, fill = sentiment)) +
    geom_bar(stat= "identity") +
    coord_flip() +
    theme(legend.position="none") +
    xlab("feature") +
    ylab("importance") +
    scale_fill_manual(values = c("#595959", "#DB2C2C")) +
  labs(
      title = "Variable Importance Scores",
      subtitle = paste("Model:",name, sep=" ")
    ) + 
  theme(
      plot.title = element_text(hjust = 0.5), 
      plot.subtitle = element_text(hjust = 0.5)
    )
} 
```

```{r modelvisualisation_variableimportance, eval = TRUE, fig.width = 10, echo = FALSE}
get_variable_importance(model, "without sentiments")
get_variable_importance(model_with_sentiment, "with sentiments")
get_variable_importance(model_only_sentiment, "sentiments only")
```

A last step we looked at the importance scores of each model - mostly focusing on the model including the sentiments. It can be observed that the afinn, syuzhet and jockers_rinker sentiment scores score high importance scores. The (permutation) importance score is calculated by (1) measuring a basline RSQ , (2) permuting the values of one feature and measure the RSQ. The importance score is the difference between the basline and the drop in overall RSQ caused by the permutation.
The plot indicates a high influence of sentiment scores, but since the model has a low RSQ, this should be perceived carefully. 